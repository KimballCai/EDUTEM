{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os, logging\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "tf.compat.v1.set_random_seed(100)\n",
    "np.random.seed(100)\n",
    "\n",
    "import keras.metrics\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping, LambdaCallback\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(application='inhos_mortality', batch_size=64, clip_max=3.0, clip_min=-3.0, compress_dim=4, data_clip=False, data_clip_max=inf, data_clip_min=-inf, dataset='physionet2012', dataset_mode='regular', debug=False, embed_dim=24, epoch=200, ffill=True, ffill_steps=48, folds=[0], gpu='0,1,2', hidden_dim=64, lr=0.001, max_timesteps=48, mode='train', model='EDUTEM', model_path='', patience=10, random=False, standardization=True, weight_decay=1e-07)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# argparser for training the model\n",
    "import argparse\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(add_help=False)\n",
    "\n",
    "    # dataset\n",
    "    parser.add_argument('--dataset', type=str, default='physionet2012', choices=['physionet2012', 'MIMIC3'],\n",
    "                        help=\"dataset\")\n",
    "    parser.add_argument('--application', type=str, default='inhos_mortality', choices=['inhos_mortality'],\n",
    "                        help=\"dataset\")\n",
    "    parser.add_argument('--folds', type=list, default=[0],\n",
    "                        help='folds id')\n",
    "    parser.add_argument('--ffill', action='store_true',default=True,\n",
    "                        help='data fillingï¼Œ ffill or None')\n",
    "    parser.add_argument('--standardization', action='store_false',default=True,\n",
    "                        help='standardization for the training dataset')\n",
    "    parser.add_argument('--data_clip', action='store', default=False,\n",
    "                        help='data clipping: decide the maximun and minimun value of the training dataset')\n",
    "    parser.add_argument('--data_clip_min', type=float, default=-1*float('inf'),\n",
    "                        help='data clipping: minimun value of the training dataset')\n",
    "    parser.add_argument('--data_clip_max', type=float, default=float('inf'),\n",
    "                        help='data clipping: maximun value of the training dataset')\n",
    "    parser.add_argument('--dataset_mode', type=str, default='regular', choices=['regular'],\n",
    "                        help=\"regular or irregular\")\n",
    "    parser.add_argument('--ffill_steps', type=int, default=48,\n",
    "                        help='data filling steps')\n",
    "    parser.add_argument('--max_timesteps', type=int, default=48,\n",
    "                        help='Time series of at most # time steps are used. Default: 48.')\n",
    "\n",
    "    # model\n",
    "    parser.add_argument('--model', type=str, default='EDUTEM', choices=['EDUTEM','EDUTEM_t','EDUTEM_f'],\n",
    "                        help=\"model\")\n",
    "    parser.add_argument('--embed_dim', type=int, default=24,\n",
    "                        help=\"embed_dim\")\n",
    "    parser.add_argument('--hidden_dim', type=int, default=64,\n",
    "                        help=\"hidden_dim\")\n",
    "    parser.add_argument('--clip_min', type=float, default=-3.0,\n",
    "                        help=\"clip_min\")\n",
    "    parser.add_argument('--clip_max', type=float, default=3.0,\n",
    "                        help=\"clip_max\")\n",
    "    parser.add_argument('--compress_dim', type=int, default=4,\n",
    "                        help='compress_dim for interaction features')\n",
    "\n",
    "    # mode\n",
    "    parser.add_argument('--mode', type=str, default=\"train\",\n",
    "                        help=\"train or eval\")\n",
    "    parser.add_argument('--model_path', type=str, default=\"\",\n",
    "                        help=\"existing model path\")\n",
    "    parser.add_argument('--debug', action='store_true',default=False,\n",
    "                        help='for backup')\n",
    "    parser.add_argument('--random', action='store_true',default=False,\n",
    "                        help='for backup')\n",
    "\n",
    "    # training configuration\n",
    "    parser.add_argument('--epoch', type=int, default=200,\n",
    "                        help='Number of epochs.')\n",
    "    parser.add_argument('--batch_size', type=int, default=64,\n",
    "                        help='Batch size.')\n",
    "    parser.add_argument('--lr', type=float, default=0.001,\n",
    "                        help='Learning rate.')\n",
    "    parser.add_argument('--weight_decay', type=float, default=1e-7,\n",
    "                        help='decrease overfitting.')\n",
    "    parser.add_argument('--patience', type=int, default=10,\n",
    "                        help='patience for earlystopping.')\n",
    "    parser.add_argument('--gpu', type=str, default=\"0,1,2\",\n",
    "                        help='GPU ids')\n",
    "\n",
    "    return parser.parse_args(args=[])\n",
    "\n",
    "args = parse_args()\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set GPU usage for tensorflow backend\n",
    "if K.backend() == 'tensorflow':\n",
    "    config = tf.compat.v1.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    tf.compat.v1.keras.backend.set_session(tf.compat.v1.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.dataset == \"physionet2012\":\n",
    "    from dataset.physionet2012.DataLoader import physonet2012_DataLoader\n",
    "elif args.dataset == \"MIMIC3\":\n",
    "    from dataset.MIMIC3.DataLoader import MIMIC3_DataLoader\n",
    "else:\n",
    "    raise FileNotFoundError(\"No such dataset: %s\" % args.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recoders can record the results of the model in each epoch\n",
    "\n",
    "# the results in the first three lines show the performance of the model which has the best bceloss on the validation set.\n",
    "# the results in the second three lines show the performance of the model which has the best AUC-ROC on the validation set.\n",
    "# the results in the last three lines show the performance of the model which has the best AUC-PR on the validation set.\n",
    "import pandas as pd\n",
    "\n",
    "class Recoder():\n",
    "    def __init__(self,label,features):\n",
    "        self.count = 0\n",
    "        self.features = features\n",
    "        self.data = {\n",
    "            f: [] for f in features\n",
    "        }\n",
    "        self.label = label\n",
    "\n",
    "    def insert(self,result):\n",
    "        self.count += 1\n",
    "        for i in self.features:\n",
    "            self.data[i].append(result[i])\n",
    "        return result\n",
    "\n",
    "    def best(self,feature,mode=max):\n",
    "        best_feature = mode(self.data[feature])\n",
    "        index_best = self.data[feature].index(best_feature)\n",
    "        return index_best\n",
    "\n",
    "    def select_index(self,index):\n",
    "        return {\n",
    "            f:\"%.4f\" % self.data[f][index] for f in self.features\n",
    "        }\n",
    "\n",
    "\n",
    "class Recoders():\n",
    "    def __init__(self,output_path,title,mode=2):\n",
    "        self.features = [\"bceloss\",\"auroc\",\"auprc\",\"acc\"] # ,\"rec1\",\"prec1\"\n",
    "        self.feature_size = len(self.features)\n",
    "        if mode == 3:\n",
    "            self.sets = [\"train\",\"valid\",\"test\"]\n",
    "        elif mode == 2:\n",
    "            self.sets = [\"train\", \"valid\"]\n",
    "        self.recoders = {}\n",
    "        for set in self.sets:\n",
    "            self.recoders[set] = Recoder(set,self.features)\n",
    "        self.count = 0\n",
    "        self.output_path = output_path\n",
    "        self.title = title\n",
    "        self.min_score = 100\n",
    "\n",
    "\n",
    "    def init_score(self,score):\n",
    "        self.min_score = score\n",
    "\n",
    "    def lower_score(self,score,delta=0):\n",
    "        if score < self.min_score+delta:\n",
    "            self.count = 0\n",
    "            self.min_score = score\n",
    "            return True\n",
    "        else:\n",
    "            self.count += 1\n",
    "            return False\n",
    "\n",
    "    def clean(self):\n",
    "        for set in self.sets:\n",
    "            self.recoders[set] = Recoder(set,self.features)\n",
    "        self.count = 0\n",
    "        self.min_score = 100\n",
    "\n",
    "    def insert(self,label,result,verbose=1):\n",
    "        self.recoders[label].insert(result)\n",
    "        if verbose:\n",
    "            log_r = \"[%s] \" % label\n",
    "            for f in self.features:\n",
    "                log_r += \"%s:%.4f \" % (f, result[f])\n",
    "            logging.info(log_r)\n",
    "            # print(log_r)\n",
    "\n",
    "    def record_to_csv(self,i_fold=0):\n",
    "        result = pd.DataFrame()\n",
    "        for roc in ['bceloss','auprc','auroc']:\n",
    "            tem = pd.DataFrame(columns=['Epoch']+self.features,index=self.sets)\n",
    "            if roc == 'bceloss':\n",
    "                func = min\n",
    "            else:\n",
    "                func = max\n",
    "            best_epoch = self.recoders[\"valid\"].best(roc, func)\n",
    "            for set in self.sets:\n",
    "                if set == \"train\":\n",
    "                    tem.loc['train', 'Epoch'] = self.recoders[\"train\"].count\n",
    "                elif set == \"valid\":\n",
    "                    tem.loc['valid', 'Epoch'] = best_epoch+1\n",
    "                elif set == \"test\":\n",
    "                    tem.loc['test', 'Epoch'] = self.recoders[\"test\"].best(roc, func)+1\n",
    "            for dataset in self.sets:\n",
    "                for f in self.features:\n",
    "                    tem.loc[dataset,f] = self.recoders[dataset].select_index(best_epoch)[f]\n",
    "            result = pd.concat([result,tem],0)\n",
    "        logging.info(result)\n",
    "        result.to_csv(self.output_path + self.title+'%d.csv'%i_fold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "EPS = 1e-10\n",
    "\n",
    "# binary_eval can evaluate binary prediction results\n",
    "def binary_eval(y_true, predictions, verbose=1):\n",
    "    predictions = np.array(predictions)\n",
    "    if len(predictions.shape) == 1:\n",
    "        predictions = np.stack([1 - predictions, predictions]).transpose((1, 0))\n",
    "\n",
    "    cf = metrics.confusion_matrix(y_true, predictions.argmax(axis=1))\n",
    "    if verbose:\n",
    "        logging.info(\"confusion matrix:\")\n",
    "        logging.info(cf)\n",
    "    cf = cf.astype(np.float32)\n",
    "\n",
    "    acc = (cf[0][0] + cf[1][1]) / np.sum(cf)\n",
    "    prec0 = cf[0][0] / (cf[0][0] + cf[1][0] + EPS)\n",
    "    prec1 = cf[1][1] / (cf[1][1] + cf[0][1] + EPS)\n",
    "    rec0 = cf[0][0] / (cf[0][0] + cf[0][1] + EPS)\n",
    "    rec1 = cf[1][1] / (cf[1][1] + cf[1][0] + EPS)\n",
    "    auroc = metrics.roc_auc_score(y_true, predictions[:, 1])\n",
    "\n",
    "    (precisions, recalls, thresholds) = metrics.precision_recall_curve(y_true, predictions[:, 1])\n",
    "    auprc = metrics.auc(recalls, precisions)\n",
    "    minpse = np.max([min(x, y) for (x, y) in zip(precisions, recalls)])\n",
    "\n",
    "    bce = []\n",
    "    for i in range(len(y_true)):\n",
    "        bce.append(-y_true[i] * np.log(predictions[i,1] + EPS) - (1 - y_true[i]) * np.log(1 - predictions[i,1] + EPS))\n",
    "    bceloss = np.mean(bce)\n",
    "\n",
    "    if verbose:\n",
    "        logging.info(\"accuracy = {}\".format(acc))\n",
    "        logging.info(\"precision class 0 = {}\".format(prec0))\n",
    "        logging.info(\"precision class 1 = {}\".format(prec1))\n",
    "        logging.info(\"recall class 0 = {}\".format(rec0))\n",
    "        logging.info(\"recall class 1 = {}\".format(rec1))\n",
    "        logging.info(\"AUC of ROC = {}\".format(auroc))\n",
    "        logging.info(\"AUC of PRC = {}\".format(auprc))\n",
    "        logging.info(\"min(+P, Se) = {}\".format(minpse))\n",
    "        logging.info(\"BCEloss = {}\".format(bceloss))\n",
    "\n",
    "    return {\"acc\": acc,\n",
    "            \"prec0\": prec0,\n",
    "            \"prec1\": prec1,\n",
    "            \"rec0\": rec0,\n",
    "            \"rec1\": rec1,\n",
    "            \"auroc\": auroc,\n",
    "            \"auprc\": auprc,\n",
    "            \"minpse\": minpse,\n",
    "            \"bceloss\": bceloss,\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.layers import Activation, Dense, Dropout, Input, Masking\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.models import load_model, Model\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from model.keras_layers import EDUTEM_f,EDUTEM_t\n",
    "\n",
    "\n",
    "def EDUTEM_net(info_dim,input_dim,output_dim,time_dim,args):\n",
    "    input_info = Input(shape=(info_dim,))\n",
    "    input_stime = Input(shape=(time_dim,))\n",
    "    input_tdata = Input(shape=(time_dim, input_dim))\n",
    "    input_tmask = Input(shape=(time_dim, input_dim))\n",
    "\n",
    "    input_list = [input_info, input_stime, input_tdata, input_tmask]\n",
    "\n",
    "    EDUTEM_f_layer = EDUTEM_f(input_dim=input_dim,\n",
    "                         embedding_dim=args.embed_dim,\n",
    "                         time_step=time_dim,\n",
    "                         compress_dim=args.compress_dim,\n",
    "                         clip_min=args.clip_min,\n",
    "                         clip_max=args.clip_max,\n",
    "                         )\n",
    "\n",
    "    EDUTEM_t_layer = EDUTEM_t(time_step=time_dim,\n",
    "                         hidden_dim=args.hidden_dim\n",
    "                         )\n",
    "\n",
    "    gru_layer = GRU(units=args.hidden_dim,\n",
    "                    activation='sigmoid',\n",
    "                    return_sequences=True,\n",
    "                    )\n",
    "\n",
    "    x = EDUTEM_f_layer([input_tdata, input_tmask])\n",
    "    x = gru_layer(x)\n",
    "    x = EDUTEM_t_layer(x)\n",
    "\n",
    "    x = Dense(units=64, activation='relu',kernel_regularizer=l2(1e-4))(x)\n",
    "    x = Dense(output_dim, activation='sigmoid')(x)\n",
    "    output_list = [x]\n",
    "    model = Model(inputs=input_list, outputs=output_list)\n",
    "    return model\n",
    "\n",
    "\n",
    "def EDUTEM_t_net(info_dim,input_dim,output_dim,time_dim,args):\n",
    "    input_info = Input(shape=(info_dim,))\n",
    "    input_stime = Input(shape=(time_dim,))\n",
    "    input_tdata = Input(shape=(time_dim, input_dim))\n",
    "    input_tmask = Input(shape=(time_dim, input_dim))\n",
    "\n",
    "    input_list = [input_info, input_stime, input_tdata, input_tmask]\n",
    "\n",
    "    EDUTEM_t_layer = EDUTEM_t(time_step=time_dim,\n",
    "                         hidden_dim=args.hidden_dim\n",
    "                         )\n",
    "\n",
    "    gru_layer = GRU(units=args.hidden_dim,\n",
    "                    activation='sigmoid',\n",
    "                    return_sequences=True,\n",
    "                    )\n",
    "\n",
    "    x = gru_layer(input_tdata)\n",
    "    x = EDUTEM_t_layer(x)\n",
    "\n",
    "    x = Dense(output_dim, activation='sigmoid')(x)\n",
    "    output_list = [x]\n",
    "    model = Model(inputs=input_list, outputs=output_list)\n",
    "    return model\n",
    "\n",
    "def EDUTEM_f_net(info_dim,input_dim,output_dim,time_dim,args):\n",
    "    input_info = Input(shape=(info_dim,))\n",
    "    input_stime = Input(shape=(time_dim,))\n",
    "    input_tdata = Input(shape=(time_dim, input_dim))\n",
    "    input_tmask = Input(shape=(time_dim, input_dim))\n",
    "\n",
    "    input_list = [input_info, input_stime, input_tdata, input_tmask]\n",
    "\n",
    "    EDUTEM_f_layer = EDUTEM_f(input_dim=input_dim,\n",
    "                         embedding_dim=args.embed_dim,\n",
    "                         time_step=time_dim,\n",
    "                         compress_dim=args.compress_dim,\n",
    "                         clip_min=args.clip_min,\n",
    "                         clip_max=args.clip_max,\n",
    "                         )\n",
    "\n",
    "    gru_layer = GRU(units=args.hidden_dim,\n",
    "                    activation='sigmoid',\n",
    "                    return_sequences=False,\n",
    "                    )\n",
    "\n",
    "    x = EDUTEM_f_layer([input_tdata, input_tmask])\n",
    "    x = gru_layer(x)\n",
    "\n",
    "    x = Dense(output_dim, activation='sigmoid')(x)\n",
    "    output_list = [x]\n",
    "    model = Model(inputs=input_list, outputs=output_list)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class main():\n",
    "    def __init__(self):\n",
    "        timestamp = datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "        self.log_path = self.set_log_path(timestamp)\n",
    "\n",
    "        handlers = [logging.FileHandler(self.log_path + 'log_{}.txt'.format(timestamp), mode='w'), logging.StreamHandler()]\n",
    "        logging.basicConfig(level=logging.INFO, datefmt='%m-%d-%y %H:%M', format='%(asctime)s:%(message)s', handlers=handlers)\n",
    "\n",
    "        logging.info('Timestamp: {}'.format(timestamp))\n",
    "        logging.info('Arguments:%s' % args)\n",
    "\n",
    "        self.sets = ['train', 'valid', 'test']\n",
    "        # sets = ['train', 'valid']\n",
    "\n",
    "        self.recoders = Recoders(self.log_path, timestamp, len(self.sets))\n",
    "\n",
    "        for i_fold in args.folds:\n",
    "            print('{}-th fold...'.format(i_fold))\n",
    "            self.dataset = self.load_dataset(i_fold)\n",
    "            self.model = self.load_model()\n",
    "            if args.mode == \"train\":\n",
    "                self.train(i_fold)\n",
    "            self.eval(i_fold)\n",
    "\n",
    "    def set_log_path(self,timestamp):\n",
    "        log_path = os.getcwd() + \"/logs/\"\n",
    "        if not os.path.exists(log_path):\n",
    "            os.mkdir(log_path)\n",
    "\n",
    "        if args.debug:\n",
    "            log_path += \"/%s_%s_debug/\" % (args.model, timestamp)\n",
    "            if not os.path.exists(log_path):\n",
    "                os.mkdir(log_path)\n",
    "            return log_path\n",
    "\n",
    "        log_path += \"/%s/\"% args.dataset\n",
    "        if not os.path.exists(log_path):\n",
    "            os.mkdir(log_path)\n",
    "\n",
    "        log_path += \"/%s/\"% args.application\n",
    "        if not os.path.exists(log_path):\n",
    "            os.mkdir(log_path)\n",
    "\n",
    "        log_path += \"/%s/\"% args.model\n",
    "        if not os.path.exists(log_path):\n",
    "            os.mkdir(log_path)\n",
    "\n",
    "        log_path += \"/%s_%s/\" % (args.model, timestamp)\n",
    "        if args.random:\n",
    "            log_path = log_path[:-1]+\"_random/\"\n",
    "        if not os.path.exists(log_path):\n",
    "            os.mkdir(log_path)\n",
    "        return log_path\n",
    "\n",
    "    def load_dataset(self, i_fold):\n",
    "        logging.info(\"[*] Loading dataset: %s\" % args.dataset)\n",
    "        if args.dataset == \"physionet2012\":\n",
    "            dataset = physonet2012_DataLoader(args=args, fold_id=i_fold, label=args.application, debug=args.debug)\n",
    "        elif args.dataset == \"MIMIC3\":\n",
    "            dataset = MIMIC3_DataLoader(args=args, fold_id=i_fold, label=args.application, debug=args.debug)\n",
    "        else:\n",
    "            raise NameError(args.dataset)\n",
    "\n",
    "        train_len = dataset.get_subset_size(\"train\")\n",
    "        valid_len = dataset.get_subset_size(\"valid\")\n",
    "        if len(self.sets) == 3:\n",
    "            test_len = dataset.get_subset_size(\"test\")\n",
    "        else:\n",
    "            test_len = 0\n",
    "        logging.info(\"train: %d valid: %d test: %d\" % (train_len, valid_len, test_len))\n",
    "        return dataset\n",
    "\n",
    "\n",
    "    def load_model(self):\n",
    "        if args.dataset_mode == \"regular\":\n",
    "            if args.model == \"EDUTEM\":\n",
    "                model = EDUTEM_net(info_dim=self.dataset.info_dim, input_dim=self.dataset.input_dim,output_dim=self.dataset.output_dim,\n",
    "                                     time_dim=48, args=args)\n",
    "            elif args.model == \"EDUTEM_t\":\n",
    "                model = EDUTEM_t_net(info_dim=self.dataset.info_dim, input_dim=self.dataset.input_dim,output_dim=self.dataset.output_dim,\n",
    "                                     time_dim=48, args=args)\n",
    "            elif args.model == \"EDUTEM_f\":\n",
    "                model = EDUTEM_f_net(info_dim=self.dataset.info_dim, input_dim=self.dataset.input_dim,output_dim=self.dataset.output_dim,\n",
    "                                     time_dim=48, args=args)\n",
    "            else:\n",
    "                raise NotImplementedError(\"No such model in regular mode: %s\" % (args.model))\n",
    "\n",
    "        model.summary(print_fn=logging.info)\n",
    "        return model\n",
    "\n",
    "\n",
    "    def eval_epoch(self, epoch, dataset, model, i_fold,save=True):\n",
    "        true_y_list = [\n",
    "            dataset.sub_label(\"train\"),dataset.sub_label(\"valid\")\n",
    "        ]\n",
    "        pred_y_list = [\n",
    "            model.predict_generator(dataset.get_generator(\"train\", shuffle=False, batch_size=args.batch_size, return_whole=False),\n",
    "                                    steps=dataset.sub_steps(\"train\", batch_size=args.batch_size)),\n",
    "            model.predict_generator(dataset.get_generator(\"valid\", shuffle=False, batch_size=args.batch_size, return_whole=False),\n",
    "                                    steps=dataset.sub_steps(\"valid\", batch_size=args.batch_size)),\n",
    "        ]\n",
    "        if len(self.sets) == 3:\n",
    "            true_y_list.append(dataset.sub_label(\"test\"))\n",
    "            pred_y_list.append(model.predict_generator(dataset.get_generator(\"test\", shuffle=False, batch_size=args.batch_size, return_whole=False),\n",
    "                                                       steps=dataset.sub_steps(\"test\", batch_size=args.batch_size)))\n",
    "\n",
    "        logging.info(\"[%s Epoch %d]\" % (args.model, epoch))\n",
    "        for index,dataset in enumerate(self.sets):\n",
    "            result = binary_eval(np.reshape(true_y_list[index],(-1)), np.reshape(pred_y_list[index],(-1)), 0)\n",
    "            self.recoders.insert(dataset, result)\n",
    "            if dataset == \"valid\" and self.recoders.lower_score(result['bceloss']) and save:\n",
    "                logging.info(\"[*] model_%d.h5 saved \"%i_fold)\n",
    "                model.save(self.log_path+'model_%d.h5'%i_fold)\n",
    "\n",
    "\n",
    "\n",
    "    def train(self, i_fold):\n",
    "        optimizer = Adam(learning_rate=args.lr,decay=0.0)\n",
    "        self.model.compile(optimizer=optimizer, loss='binary_crossentropy',metrics=[keras.metrics.BinaryCrossentropy()])\n",
    "\n",
    "        self.model.fit_generator(\n",
    "            generator=self.dataset.get_generator(\"train\", shuffle=True, batch_size=args.batch_size, return_whole=True),\n",
    "            steps_per_epoch=self.dataset.sub_steps(\"train\", batch_size=args.batch_size),\n",
    "            epochs=args.epoch,\n",
    "            verbose=1,\n",
    "            validation_data=self.dataset.get_generator(\"valid\", shuffle=False, batch_size=args.batch_size, return_whole=True),\n",
    "            validation_steps=self.dataset.sub_steps(\"valid\", batch_size=args.batch_size),\n",
    "            callbacks=[\n",
    "                LambdaCallback(on_epoch_end=lambda epoch, logs: self.eval_epoch(epoch + 1, self.dataset, self.model, i_fold)),\n",
    "                EarlyStopping(monitor=\"val_binary_crossentropy\",patience=args.patience,mode=\"min\")\n",
    "                # reduce_lr,\n",
    "            ]\n",
    "        )\n",
    "        self.recoders.record_to_csv(i_fold)\n",
    "        self.recoders.clean()\n",
    "\n",
    "\n",
    "    def eval(self, i_fold):\n",
    "        if args.mode == \"eval\":\n",
    "            if args.model_path != \"\" and os.path.exists(args.model_path):\n",
    "                self.model.load_weights(args.model_path)\n",
    "            else:\n",
    "                raise FileNotFoundError(\"There is no such file for the model: %s\" % args.model_path)\n",
    "\n",
    "        elif args.mode == \"train\":\n",
    "            self.model.load_weights(self.log_path+'model_%d.h5'%i_fold)\n",
    "\n",
    "        logging.info(\"[Eval]\")\n",
    "        self.eval_epoch(0, self.dataset, self.model, i_fold, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-08-21 11:40:Timestamp: 20210208114032\n",
      "02-08-21 11:40:Arguments:Namespace(application='inhos_mortality', batch_size=64, clip_max=3.0, clip_min=-3.0, compress_dim=4, data_clip=False, data_clip_max=inf, data_clip_min=-inf, dataset='physionet2012', dataset_mode='regular', debug=False, embed_dim=24, epoch=200, ffill=True, ffill_steps=48, folds=[0], gpu='0,1,2', hidden_dim=64, lr=0.001, max_timesteps=48, mode='train', model='EDUTEM', model_path='', patience=10, random=False, standardization=True, weight_decay=1e-07)\n",
      "02-08-21 11:40:[*] Loading dataset: physionet2012\n",
      "02-08-21 11:40:fold path: inhos_mortality_folds.npz\n",
      "02-08-21 11:40:train: [150491 143937 148710 140049 156691]\n",
      "  0%|          | 23/9600 [00:00<00:42, 227.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-th fold...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9600/9600 [00:33<00:00, 288.48it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1200/1200 [00:04<00:00, 290.13it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1200/1200 [00:04<00:00, 282.08it/s]\n",
      "02-08-21 11:41:train: 9600 valid: 1200 test: 1200\n",
      "02-08-21 11:41:Model: \"model_1\"\n",
      "02-08-21 11:41:__________________________________________________________________________________________________\n",
      "02-08-21 11:41:Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "02-08-21 11:41:==================================================================================================\n",
      "02-08-21 11:41:input_3 (InputLayer)            (None, 48, 37)       0                                            \n",
      "02-08-21 11:41:__________________________________________________________________________________________________\n",
      "02-08-21 11:41:input_4 (InputLayer)            (None, 48, 37)       0                                            \n",
      "02-08-21 11:41:__________________________________________________________________________________________________\n",
      "02-08-21 11:41:edutem_f_1 (EDUTEM_f)           (None, 48, 148)      3781        input_3[0][0]                    \n",
      "02-08-21 11:41:                                                                 input_4[0][0]                    \n",
      "02-08-21 11:41:__________________________________________________________________________________________________\n",
      "02-08-21 11:41:gru_1 (GRU)                     (None, 48, 64)       40896       edutem_f_1[0][0]                 \n",
      "02-08-21 11:41:__________________________________________________________________________________________________\n",
      "02-08-21 11:41:edutem_t_1 (EDUTEM_t)           (None, 128)          65          gru_1[0][0]                      \n",
      "02-08-21 11:41:__________________________________________________________________________________________________\n",
      "02-08-21 11:41:dense_1 (Dense)                 (None, 64)           8256        edutem_t_1[0][0]                 \n",
      "02-08-21 11:41:__________________________________________________________________________________________________\n",
      "02-08-21 11:41:dense_2 (Dense)                 (None, 1)            65          dense_1[0][0]                    \n",
      "02-08-21 11:41:==================================================================================================\n",
      "02-08-21 11:41:Total params: 53,063\n",
      "02-08-21 11:41:Trainable params: 53,063\n",
      "02-08-21 11:41:Non-trainable params: 0\n",
      "02-08-21 11:41:__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "150/150 [==============================] - 16s 107ms/step - loss: 0.4006 - binary_crossentropy: 0.3946 - val_loss: 0.4489 - val_binary_crossentropy: 0.3632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-08-21 11:41:[EDUTEM Epoch 1]\n",
      "02-08-21 11:41:[train] bceloss:0.3636 auroc:0.7511 auprc:0.3603 acc:0.8585 \n",
      "02-08-21 11:41:[valid] bceloss:0.3632 auroc:0.7536 auprc:0.3953 acc:0.8583 \n",
      "02-08-21 11:41:[*] model_0.h5 saved \n",
      "02-08-21 11:41:[test] bceloss:0.3715 auroc:0.7190 auprc:0.3733 acc:0.8592 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3381 - binary_crossentropy: 0.3334 - val_loss: 0.4398 - val_binary_crossentropy: 0.3297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-08-21 11:42:[EDUTEM Epoch 2]\n",
      "02-08-21 11:42:[train] bceloss:0.3143 auroc:0.8388 auprc:0.4872 acc:0.8696 \n",
      "02-08-21 11:42:[valid] bceloss:0.3297 auroc:0.8105 auprc:0.4792 acc:0.8675 \n",
      "02-08-21 11:42:[*] model_0.h5 saved \n",
      "02-08-21 11:42:[test] bceloss:0.3199 auroc:0.8374 auprc:0.4702 acc:0.8658 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/200\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3133 - binary_crossentropy: 0.3089 - val_loss: 0.4030 - val_binary_crossentropy: 0.3226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-08-21 11:42:[EDUTEM Epoch 3]\n",
      "02-08-21 11:42:[train] bceloss:0.3090 auroc:0.8516 auprc:0.5185 acc:0.8693 \n",
      "02-08-21 11:42:[valid] bceloss:0.3226 auroc:0.8245 auprc:0.5019 acc:0.8725 \n",
      "02-08-21 11:42:[*] model_0.h5 saved \n",
      "02-08-21 11:42:[test] bceloss:0.3091 auroc:0.8517 auprc:0.4907 acc:0.8683 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/200\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3066 - binary_crossentropy: 0.3024 - val_loss: 0.4155 - val_binary_crossentropy: 0.3098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-08-21 11:42:[EDUTEM Epoch 4]\n",
      "02-08-21 11:42:[train] bceloss:0.2952 auroc:0.8567 auprc:0.5302 acc:0.8769 \n",
      "02-08-21 11:42:[valid] bceloss:0.3098 auroc:0.8335 auprc:0.5153 acc:0.8800 \n",
      "02-08-21 11:42:[*] model_0.h5 saved \n",
      "02-08-21 11:42:[test] bceloss:0.2984 auroc:0.8580 auprc:0.4966 acc:0.8683 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/200\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3057 - binary_crossentropy: 0.3017 - val_loss: 0.4132 - val_binary_crossentropy: 0.3072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-08-21 11:43:[EDUTEM Epoch 5]\n",
      "02-08-21 11:43:[train] bceloss:0.2918 auroc:0.8611 auprc:0.5409 acc:0.8784 \n",
      "02-08-21 11:43:[valid] bceloss:0.3072 auroc:0.8375 auprc:0.5219 acc:0.8808 \n",
      "02-08-21 11:43:[*] model_0.h5 saved \n",
      "02-08-21 11:43:[test] bceloss:0.2956 auroc:0.8619 auprc:0.5066 acc:0.8733 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/200\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.2991 - binary_crossentropy: 0.2952 - val_loss: 0.3964 - val_binary_crossentropy: 0.3036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-08-21 11:43:[EDUTEM Epoch 6]\n",
      "02-08-21 11:43:[train] bceloss:0.2902 auroc:0.8639 auprc:0.5477 acc:0.8796 \n",
      "02-08-21 11:43:[valid] bceloss:0.3036 auroc:0.8409 auprc:0.5295 acc:0.8800 \n",
      "02-08-21 11:43:[*] model_0.h5 saved \n",
      "02-08-21 11:43:[test] bceloss:0.2924 auroc:0.8644 auprc:0.5136 acc:0.8750 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/200\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.2981 - binary_crossentropy: 0.2943 - val_loss: 0.4295 - val_binary_crossentropy: 0.3083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-08-21 11:44:[EDUTEM Epoch 7]\n",
      "02-08-21 11:44:[train] bceloss:0.2928 auroc:0.8649 auprc:0.5498 acc:0.8788 \n",
      "02-08-21 11:44:[valid] bceloss:0.3083 auroc:0.8435 auprc:0.5355 acc:0.8775 \n",
      "02-08-21 11:44:[test] bceloss:0.2996 auroc:0.8640 auprc:0.5130 acc:0.8683 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/200\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.2968 - binary_crossentropy: 0.2932 - val_loss: 0.4018 - val_binary_crossentropy: 0.3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-08-21 11:44:[EDUTEM Epoch 8]\n",
      "02-08-21 11:44:[train] bceloss:0.2865 auroc:0.8666 auprc:0.5541 acc:0.8816 \n",
      "02-08-21 11:44:[valid] bceloss:0.3000 auroc:0.8447 auprc:0.5388 acc:0.8850 \n",
      "02-08-21 11:44:[*] model_0.h5 saved \n",
      "02-08-21 11:44:[test] bceloss:0.2902 auroc:0.8654 auprc:0.5181 acc:0.8767 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/200\n",
      "150/150 [==============================] - 15s 102ms/step - loss: 0.2939 - binary_crossentropy: 0.2904 - val_loss: 0.4093 - val_binary_crossentropy: 0.3224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-08-21 11:44:[EDUTEM Epoch 9]\n",
      "02-08-21 11:44:[train] bceloss:0.3109 auroc:0.8680 auprc:0.5584 acc:0.8675 \n",
      "02-08-21 11:44:[valid] bceloss:0.3224 auroc:0.8430 auprc:0.5363 acc:0.8642 \n",
      "02-08-21 11:44:[test] bceloss:0.3074 auroc:0.8700 auprc:0.5175 acc:0.8708 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/200\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.2958 - binary_crossentropy: 0.2925 - val_loss: 0.4291 - val_binary_crossentropy: 0.3071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-08-21 11:45:[EDUTEM Epoch 10]\n",
      "02-08-21 11:45:[train] bceloss:0.2893 auroc:0.8691 auprc:0.5596 acc:0.8776 \n",
      "02-08-21 11:45:[valid] bceloss:0.3071 auroc:0.8453 auprc:0.5402 acc:0.8783 \n",
      "02-08-21 11:45:[test] bceloss:0.2949 auroc:0.8686 auprc:0.5287 acc:0.8692 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/200\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.2909 - binary_crossentropy: 0.2877 - val_loss: 0.4184 - val_binary_crossentropy: 0.3020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-08-21 11:45:[EDUTEM Epoch 11]\n",
      "02-08-21 11:45:[train] bceloss:0.2845 auroc:0.8700 auprc:0.5633 acc:0.8791 \n",
      "02-08-21 11:45:[valid] bceloss:0.3020 auroc:0.8440 auprc:0.5371 acc:0.8800 \n",
      "02-08-21 11:45:[test] bceloss:0.2873 auroc:0.8711 auprc:0.5271 acc:0.8725 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/200\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.2915 - binary_crossentropy: 0.2884 - val_loss: 0.4139 - val_binary_crossentropy: 0.2984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-08-21 11:45:[EDUTEM Epoch 12]\n",
      "02-08-21 11:45:[train] bceloss:0.2844 auroc:0.8701 auprc:0.5645 acc:0.8770 \n",
      "02-08-21 11:45:[valid] bceloss:0.2984 auroc:0.8478 auprc:0.5464 acc:0.8808 \n",
      "02-08-21 11:45:[*] model_0.h5 saved \n",
      "02-08-21 11:45:[test] bceloss:0.2878 auroc:0.8690 auprc:0.5195 acc:0.8692 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/200\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.2906 - binary_crossentropy: 0.2875 - val_loss: 0.4038 - val_binary_crossentropy: 0.2970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-08-21 11:46:[EDUTEM Epoch 13]\n",
      "02-08-21 11:46:[train] bceloss:0.2829 auroc:0.8702 auprc:0.5660 acc:0.8824 \n",
      "02-08-21 11:46:[valid] bceloss:0.2970 auroc:0.8484 auprc:0.5491 acc:0.8867 \n",
      "02-08-21 11:46:[*] model_0.h5 saved \n",
      "02-08-21 11:46:[test] bceloss:0.2893 auroc:0.8665 auprc:0.5175 acc:0.8708 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/200\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.2937 - binary_crossentropy: 0.2907 - val_loss: 0.4190 - val_binary_crossentropy: 0.3009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-08-21 11:46:[EDUTEM Epoch 14]\n",
      "02-08-21 11:46:[train] bceloss:0.2835 auroc:0.8725 auprc:0.5691 acc:0.8815 \n",
      "02-08-21 11:46:[valid] bceloss:0.3009 auroc:0.8483 auprc:0.5482 acc:0.8825 \n",
      "02-08-21 11:46:[test] bceloss:0.2890 auroc:0.8710 auprc:0.5300 acc:0.8708 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/200\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.2909 - binary_crossentropy: 0.2880 - val_loss: 0.4521 - val_binary_crossentropy: 0.3132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-08-21 11:47:[EDUTEM Epoch 15]\n",
      "02-08-21 11:47:[train] bceloss:0.2923 auroc:0.8720 auprc:0.5688 acc:0.8786 \n",
      "02-08-21 11:47:[valid] bceloss:0.3132 auroc:0.8458 auprc:0.5425 acc:0.8767 \n",
      "02-08-21 11:47:[test] bceloss:0.2965 auroc:0.8741 auprc:0.5366 acc:0.8717 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/200\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.2886 - binary_crossentropy: 0.2858 - val_loss: 0.4390 - val_binary_crossentropy: 0.3058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-08-21 11:47:[EDUTEM Epoch 16]\n",
      "02-08-21 11:47:[train] bceloss:0.2849 auroc:0.8744 auprc:0.5755 acc:0.8815 \n",
      "02-08-21 11:47:[valid] bceloss:0.3058 auroc:0.8489 auprc:0.5492 acc:0.8817 \n",
      "02-08-21 11:47:[test] bceloss:0.2904 auroc:0.8742 auprc:0.5326 acc:0.8717 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/200\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.2880 - binary_crossentropy: 0.2853 - val_loss: 0.4639 - val_binary_crossentropy: 0.3252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-08-21 11:47:[EDUTEM Epoch 17]\n",
      "02-08-21 11:47:[train] bceloss:0.3019 auroc:0.8755 auprc:0.5769 acc:0.8761 \n",
      "02-08-21 11:47:[valid] bceloss:0.3252 auroc:0.8492 auprc:0.5478 acc:0.8725 \n",
      "02-08-21 11:47:[test] bceloss:0.3100 auroc:0.8745 auprc:0.5390 acc:0.8700 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/200\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.2880 - binary_crossentropy: 0.2853 - val_loss: 0.4122 - val_binary_crossentropy: 0.2970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-08-21 11:48:[EDUTEM Epoch 18]\n",
      "02-08-21 11:48:[train] bceloss:0.2794 auroc:0.8765 auprc:0.5817 acc:0.8824 \n",
      "02-08-21 11:48:[valid] bceloss:0.2970 auroc:0.8511 auprc:0.5546 acc:0.8858 \n",
      "02-08-21 11:48:[test] bceloss:0.2843 auroc:0.8756 auprc:0.5405 acc:0.8725 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/200\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.2834 - binary_crossentropy: 0.2808 - val_loss: 0.3965 - val_binary_crossentropy: 0.2948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-08-21 11:48:[EDUTEM Epoch 19]\n",
      "02-08-21 11:48:[train] bceloss:0.2792 auroc:0.8772 auprc:0.5862 acc:0.8814 \n",
      "02-08-21 11:48:[valid] bceloss:0.2948 auroc:0.8524 auprc:0.5605 acc:0.8808 \n",
      "02-08-21 11:48:[*] model_0.h5 saved \n",
      "02-08-21 11:48:[test] bceloss:0.2837 auroc:0.8739 auprc:0.5347 acc:0.8792 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/200\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.2835 - binary_crossentropy: 0.2810 - val_loss: 0.4269 - val_binary_crossentropy: 0.2982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-08-21 11:49:[EDUTEM Epoch 20]\n",
      "02-08-21 11:49:[train] bceloss:0.2780 auroc:0.8778 auprc:0.5855 acc:0.8847 \n",
      "02-08-21 11:49:[valid] bceloss:0.2982 auroc:0.8517 auprc:0.5567 acc:0.8858 \n",
      "02-08-21 11:49:[test] bceloss:0.2832 auroc:0.8779 auprc:0.5444 acc:0.8750 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/200\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.2826 - binary_crossentropy: 0.2801 - val_loss: 0.4205 - val_binary_crossentropy: 0.2957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-08-21 11:49:[EDUTEM Epoch 21]\n",
      "02-08-21 11:49:[train] bceloss:0.2748 auroc:0.8794 auprc:0.5917 acc:0.8854 \n",
      "02-08-21 11:49:[valid] bceloss:0.2957 auroc:0.8527 auprc:0.5610 acc:0.8875 \n",
      "02-08-21 11:49:[test] bceloss:0.2826 auroc:0.8757 auprc:0.5415 acc:0.8775 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/200\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.2813 - binary_crossentropy: 0.2789 - val_loss: 0.4037 - val_binary_crossentropy: 0.3112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-08-21 11:49:[EDUTEM Epoch 22]\n",
      "02-08-21 11:49:[train] bceloss:0.2954 auroc:0.8802 auprc:0.5956 acc:0.8743 \n",
      "02-08-21 11:49:[valid] bceloss:0.3112 auroc:0.8509 auprc:0.5577 acc:0.8692 \n",
      "02-08-21 11:49:[test] bceloss:0.2952 auroc:0.8778 auprc:0.5448 acc:0.8675 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/200\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.2840 - binary_crossentropy: 0.2816 - val_loss: 0.4434 - val_binary_crossentropy: 0.3017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-08-21 11:50:[EDUTEM Epoch 23]\n",
      "02-08-21 11:50:[train] bceloss:0.2772 auroc:0.8807 auprc:0.5949 acc:0.8859 \n",
      "02-08-21 11:50:[valid] bceloss:0.3017 auroc:0.8517 auprc:0.5572 acc:0.8825 \n",
      "02-08-21 11:50:[test] bceloss:0.2824 auroc:0.8819 auprc:0.5551 acc:0.8767 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/200\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.2793 - binary_crossentropy: 0.2770 - val_loss: 0.4342 - val_binary_crossentropy: 0.2953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-08-21 11:50:[EDUTEM Epoch 24]\n",
      "02-08-21 11:50:[train] bceloss:0.2724 auroc:0.8824 auprc:0.6021 acc:0.8877 \n",
      "02-08-21 11:50:[valid] bceloss:0.2953 auroc:0.8555 auprc:0.5628 acc:0.8850 \n",
      "02-08-21 11:50:[test] bceloss:0.2798 auroc:0.8810 auprc:0.5569 acc:0.8808 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/200\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.2791 - binary_crossentropy: 0.2768 - val_loss: 0.4300 - val_binary_crossentropy: 0.3009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-08-21 11:51:[EDUTEM Epoch 25]\n",
      "02-08-21 11:51:[train] bceloss:0.2763 auroc:0.8836 auprc:0.6052 acc:0.8839 \n",
      "02-08-21 11:51:[valid] bceloss:0.3009 auroc:0.8566 auprc:0.5637 acc:0.8858 \n",
      "02-08-21 11:51:[test] bceloss:0.2864 auroc:0.8815 auprc:0.5541 acc:0.8775 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/200\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.2768 - binary_crossentropy: 0.2746 - val_loss: 0.4337 - val_binary_crossentropy: 0.2995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-08-21 11:51:[EDUTEM Epoch 26]\n",
      "02-08-21 11:51:[train] bceloss:0.2738 auroc:0.8843 auprc:0.6064 acc:0.8849 \n",
      "02-08-21 11:51:[valid] bceloss:0.2995 auroc:0.8532 auprc:0.5595 acc:0.8833 \n",
      "02-08-21 11:51:[test] bceloss:0.2788 auroc:0.8858 auprc:0.5694 acc:0.8783 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/200\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.2753 - binary_crossentropy: 0.2731 - val_loss: 0.4361 - val_binary_crossentropy: 0.2982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-08-21 11:51:[EDUTEM Epoch 27]\n",
      "02-08-21 11:51:[train] bceloss:0.2708 auroc:0.8858 auprc:0.6119 acc:0.8855 \n",
      "02-08-21 11:51:[valid] bceloss:0.2982 auroc:0.8532 auprc:0.5595 acc:0.8825 \n",
      "02-08-21 11:51:[test] bceloss:0.2770 auroc:0.8865 auprc:0.5700 acc:0.8833 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/200\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.2772 - binary_crossentropy: 0.2750 - val_loss: 0.4221 - val_binary_crossentropy: 0.2921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-08-21 11:52:[EDUTEM Epoch 28]\n",
      "02-08-21 11:52:[train] bceloss:0.2663 auroc:0.8865 auprc:0.6165 acc:0.8875 \n",
      "02-08-21 11:52:[valid] bceloss:0.2921 auroc:0.8563 auprc:0.5650 acc:0.8833 \n",
      "02-08-21 11:52:[*] model_0.h5 saved \n",
      "02-08-21 11:52:[test] bceloss:0.2747 auroc:0.8836 auprc:0.5636 acc:0.8850 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/200\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.2748 - binary_crossentropy: 0.2726 - val_loss: 0.4446 - val_binary_crossentropy: 0.2921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-08-21 11:52:[EDUTEM Epoch 29]\n",
      "02-08-21 11:52:[train] bceloss:0.2657 auroc:0.8872 auprc:0.6201 acc:0.8908 \n",
      "02-08-21 11:52:[valid] bceloss:0.2921 auroc:0.8564 auprc:0.5666 acc:0.8833 \n",
      "02-08-21 11:52:[*] model_0.h5 saved \n",
      "02-08-21 11:52:[test] bceloss:0.2742 auroc:0.8852 auprc:0.5683 acc:0.8842 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/200\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.2712 - binary_crossentropy: 0.2690 - val_loss: 0.4583 - val_binary_crossentropy: 0.3029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-08-21 11:52:[EDUTEM Epoch 30]\n",
      "02-08-21 11:52:[train] bceloss:0.2735 auroc:0.8888 auprc:0.6235 acc:0.8874 \n",
      "02-08-21 11:52:[valid] bceloss:0.3029 auroc:0.8592 auprc:0.5696 acc:0.8842 \n",
      "02-08-21 11:52:[test] bceloss:0.2868 auroc:0.8852 auprc:0.5725 acc:0.8808 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/200\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.2721 - binary_crossentropy: 0.2700 - val_loss: 0.4286 - val_binary_crossentropy: 0.2916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-08-21 11:53:[EDUTEM Epoch 31]\n",
      "02-08-21 11:53:[train] bceloss:0.2640 auroc:0.8907 auprc:0.6287 acc:0.8892 \n",
      "02-08-21 11:53:[valid] bceloss:0.2916 auroc:0.8589 auprc:0.5690 acc:0.8817 \n",
      "02-08-21 11:53:[*] model_0.h5 saved \n",
      "02-08-21 11:53:[test] bceloss:0.2741 auroc:0.8870 auprc:0.5754 acc:0.8892 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/200\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.2700 - binary_crossentropy: 0.2679 - val_loss: 0.4467 - val_binary_crossentropy: 0.3011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-08-21 11:53:[EDUTEM Epoch 32]\n",
      "02-08-21 11:53:[train] bceloss:0.2698 auroc:0.8912 auprc:0.6312 acc:0.8879 \n",
      "02-08-21 11:53:[valid] bceloss:0.3011 auroc:0.8600 auprc:0.5721 acc:0.8842 \n",
      "02-08-21 11:53:[test] bceloss:0.2859 auroc:0.8850 auprc:0.5699 acc:0.8842 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/200\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.2691 - binary_crossentropy: 0.2670 - val_loss: 0.4428 - val_binary_crossentropy: 0.2887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-08-21 11:54:[EDUTEM Epoch 33]\n",
      "02-08-21 11:54:[train] bceloss:0.2605 auroc:0.8916 auprc:0.6331 acc:0.8922 \n",
      "02-08-21 11:54:[valid] bceloss:0.2887 auroc:0.8611 auprc:0.5739 acc:0.8817 \n",
      "02-08-21 11:54:[*] model_0.h5 saved \n",
      "02-08-21 11:54:[test] bceloss:0.2744 auroc:0.8847 auprc:0.5719 acc:0.8817 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/200\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.2707 - binary_crossentropy: 0.2686 - val_loss: 0.4491 - val_binary_crossentropy: 0.2934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-08-21 11:54:[EDUTEM Epoch 34]\n",
      "02-08-21 11:54:[train] bceloss:0.2615 auroc:0.8930 auprc:0.6368 acc:0.8910 \n",
      "02-08-21 11:54:[valid] bceloss:0.2934 auroc:0.8590 auprc:0.5638 acc:0.8817 \n",
      "02-08-21 11:54:[test] bceloss:0.2739 auroc:0.8882 auprc:0.5787 acc:0.8892 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/200\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.2676 - binary_crossentropy: 0.2656 - val_loss: 0.4513 - val_binary_crossentropy: 0.2954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-08-21 11:54:[EDUTEM Epoch 35]\n",
      "02-08-21 11:54:[train] bceloss:0.2592 auroc:0.8949 auprc:0.6441 acc:0.8913 \n",
      "02-08-21 11:54:[valid] bceloss:0.2954 auroc:0.8581 auprc:0.5631 acc:0.8825 \n",
      "02-08-21 11:54:[test] bceloss:0.2758 auroc:0.8873 auprc:0.5754 acc:0.8892 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/200\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.2644 - binary_crossentropy: 0.2624 - val_loss: 0.4160 - val_binary_crossentropy: 0.2916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-08-21 11:55:[EDUTEM Epoch 36]\n",
      "02-08-21 11:55:[train] bceloss:0.2614 auroc:0.8957 auprc:0.6462 acc:0.8906 \n",
      "02-08-21 11:55:[valid] bceloss:0.2916 auroc:0.8604 auprc:0.5655 acc:0.8758 \n",
      "02-08-21 11:55:[test] bceloss:0.2769 auroc:0.8835 auprc:0.5714 acc:0.8792 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/200\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.2651 - binary_crossentropy: 0.2631 - val_loss: 0.4615 - val_binary_crossentropy: 0.3035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-08-21 11:55:[EDUTEM Epoch 37]\n",
      "02-08-21 11:55:[train] bceloss:0.2640 auroc:0.8971 auprc:0.6510 acc:0.8915 \n",
      "02-08-21 11:55:[valid] bceloss:0.3035 auroc:0.8593 auprc:0.5679 acc:0.8792 \n",
      "02-08-21 11:55:[test] bceloss:0.2841 auroc:0.8881 auprc:0.5801 acc:0.8842 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/200\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.2639 - binary_crossentropy: 0.2619 - val_loss: 0.4362 - val_binary_crossentropy: 0.2971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-08-21 11:56:[EDUTEM Epoch 38]\n",
      "02-08-21 11:56:[train] bceloss:0.2566 auroc:0.8978 auprc:0.6517 acc:0.8935 \n",
      "02-08-21 11:56:[valid] bceloss:0.2971 auroc:0.8590 auprc:0.5634 acc:0.8792 \n",
      "02-08-21 11:56:[test] bceloss:0.2784 auroc:0.8865 auprc:0.5740 acc:0.8833 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/200\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.2613 - binary_crossentropy: 0.2593 - val_loss: 0.4316 - val_binary_crossentropy: 0.2974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-08-21 11:56:[EDUTEM Epoch 39]\n",
      "02-08-21 11:56:[train] bceloss:0.2560 auroc:0.8994 auprc:0.6595 acc:0.8911 \n",
      "02-08-21 11:56:[valid] bceloss:0.2974 auroc:0.8579 auprc:0.5556 acc:0.8775 \n",
      "02-08-21 11:56:[test] bceloss:0.2772 auroc:0.8843 auprc:0.5715 acc:0.8775 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/200\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.2605 - binary_crossentropy: 0.2585 - val_loss: 0.4516 - val_binary_crossentropy: 0.2972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-08-21 11:56:[EDUTEM Epoch 40]\n",
      "02-08-21 11:56:[train] bceloss:0.2531 auroc:0.9007 auprc:0.6599 acc:0.8945 \n",
      "02-08-21 11:56:[valid] bceloss:0.2972 auroc:0.8584 auprc:0.5604 acc:0.8750 \n",
      "02-08-21 11:56:[test] bceloss:0.2761 auroc:0.8866 auprc:0.5768 acc:0.8908 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/200\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.2598 - binary_crossentropy: 0.2578 - val_loss: 0.4651 - val_binary_crossentropy: 0.3001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-08-21 11:57:[EDUTEM Epoch 41]\n",
      "02-08-21 11:57:[train] bceloss:0.2537 auroc:0.9015 auprc:0.6634 acc:0.8956 \n",
      "02-08-21 11:57:[valid] bceloss:0.3001 auroc:0.8599 auprc:0.5649 acc:0.8775 \n",
      "02-08-21 11:57:[test] bceloss:0.2816 auroc:0.8849 auprc:0.5734 acc:0.8883 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/200\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.2605 - binary_crossentropy: 0.2586 - val_loss: 0.4436 - val_binary_crossentropy: 0.2925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-08-21 11:57:[EDUTEM Epoch 42]\n",
      "02-08-21 11:57:[train] bceloss:0.2497 auroc:0.9025 auprc:0.6674 acc:0.8973 \n",
      "02-08-21 11:57:[valid] bceloss:0.2925 auroc:0.8579 auprc:0.5517 acc:0.8800 \n",
      "02-08-21 11:57:[test] bceloss:0.2766 auroc:0.8812 auprc:0.5651 acc:0.8842 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/200\n",
      "150/150 [==============================] - 15s 102ms/step - loss: 0.2558 - binary_crossentropy: 0.2538 - val_loss: 0.4315 - val_binary_crossentropy: 0.2970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02-08-21 11:57:[EDUTEM Epoch 43]\n",
      "02-08-21 11:57:[train] bceloss:0.2488 auroc:0.9051 auprc:0.6762 acc:0.8999 \n",
      "02-08-21 11:57:[valid] bceloss:0.2970 auroc:0.8536 auprc:0.5463 acc:0.8808 \n",
      "02-08-21 11:57:[test] bceloss:0.2752 auroc:0.8837 auprc:0.5701 acc:0.8825 \n",
      "02-08-21 11:57:      Epoch bceloss   auroc   auprc     acc\n",
      "train    43  0.2605  0.8916  0.6331  0.8922\n",
      "valid    33  0.2887  0.8611  0.5739  0.8817\n",
      "test     34  0.2744  0.8847  0.5719  0.8817\n",
      "train    43  0.2605  0.8916  0.6331  0.8922\n",
      "valid    33  0.2887  0.8611  0.5739  0.8817\n",
      "test     37  0.2744  0.8847  0.5719  0.8817\n",
      "train    43  0.2605  0.8916  0.6331  0.8922\n",
      "valid    33  0.2887  0.8611  0.5739  0.8817\n",
      "test     34  0.2744  0.8847  0.5719  0.8817\n",
      "02-08-21 11:57:[Eval]\n",
      "02-08-21 11:58:[EDUTEM Epoch 0]\n",
      "02-08-21 11:58:[train] bceloss:0.2605 auroc:0.8916 auprc:0.6331 acc:0.8922 \n",
      "02-08-21 11:58:[valid] bceloss:0.2887 auroc:0.8611 auprc:0.5739 acc:0.8817 \n",
      "02-08-21 11:58:[test] bceloss:0.2744 auroc:0.8847 auprc:0.5719 acc:0.8817 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.main at 0x7f6e7c5551d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "                        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert",
   "language": "python",
   "name": "bert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
