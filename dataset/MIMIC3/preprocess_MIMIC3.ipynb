{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import datetime\n",
    "from rich.progress import track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 184 220739\n",
    "GCS_eye = {\n",
    "    \"Spontaneously\": 4,\n",
    "    \"To Speech\": 3,\n",
    "    \"To Pain\": 2,\n",
    "    \"None\": 1,\n",
    "}\n",
    "# 454 223901\n",
    "GCS_motor = {\n",
    "    \"Obeys Commands\": 6,\n",
    "    \"Localizes Pain\": 5,\n",
    "    \"Flex-withdraws\": 4,\n",
    "    \"Abnormal Flexion\": 3,\n",
    "    \"Abnormal extension\": 2,\n",
    "    \"No response\":1,    \n",
    "}\n",
    "# 723 223900\n",
    "# 1.0 ET/Trach, 1 No Response, 2 Incomp sounds, 3 Inapprop words, 4 Confused, 5 Oriented\n",
    "GCS_verbal = {\n",
    "    \"Oriented\": 5,\n",
    "    \"Confused\": 4,\n",
    "    \"Inappropriate Words\": 3,\n",
    "    \"Incomprehensible sounds\": 2,\n",
    "    \"No Response-ETT\": 1,\n",
    "    \"No Response\": 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76,\n",
       " 37,\n",
       " ['Albumin',\n",
       "  'ALP',\n",
       "  'ALT',\n",
       "  'AST',\n",
       "  'Bilirubin',\n",
       "  'BUN',\n",
       "  'Cholesterol',\n",
       "  'Creatinine',\n",
       "  'DiasABP',\n",
       "  'FiO2',\n",
       "  'GCS',\n",
       "  'Glucose',\n",
       "  'HCO3',\n",
       "  'HCT',\n",
       "  'HR',\n",
       "  'K',\n",
       "  'Lactate',\n",
       "  'Mg',\n",
       "  'MAP',\n",
       "  'Na',\n",
       "  'NIDiasABP',\n",
       "  'NIMAP',\n",
       "  'NISysABP',\n",
       "  'PaCO2',\n",
       "  'PaO2',\n",
       "  'pH',\n",
       "  'Platelets',\n",
       "  'RespRate',\n",
       "  'SaO2',\n",
       "  'SysABP',\n",
       "  'Temp',\n",
       "  'TropI',\n",
       "  'TropT',\n",
       "  'Urine',\n",
       "  'WBC',\n",
       "  'Weight',\n",
       "  'Mech'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IABP Mean [224, 224322]\n",
    "# pCO2_Blood_Blood Gas [50818]\n",
    "# Platelets [828, 30006, 225170]\n",
    "\n",
    "mapping_dict = {\n",
    "    \"Albumin\": [50862],\n",
    "    \"ALP\": [50863],\n",
    "    \"ALT\": [50861],\n",
    "    \"AST\": [50878],\n",
    "    \"Bilirubin\": [50885],\n",
    "    \"BUN\": [51006],\n",
    "    \"Cholesterol\": [50907],\n",
    "    \"Creatinine\": [50912],\n",
    "    \"DiasABP\": [8368,8555,220051],\n",
    "    \"FiO2\": [2981, 3420, 3422, 223835],\n",
    "    \"GCS\": [198,223901,223900,220739], # 198 = 184 + 454 + 723\n",
    "    \"Glucose\": [807,811,1529,3745,3744,225664,220621,226537,50809,50931],\n",
    "    \"HCO3\": [50882],\n",
    "    \"HCT\": [51221],\n",
    "    \"HR\": [211, 220045],\n",
    "    \"K\": [50971],\n",
    "    \"Lactate\": [50813],\n",
    "    \"Mg\": [50960],\n",
    "    \"MAP\": [52,6702,220052],\n",
    "    \"Na\": [50983],\n",
    "    \"NIDiasABP\": [8441,220180],\n",
    "    \"NIMAP\":[456, 220181],\n",
    "    \"NISysABP\": [455,220179],\n",
    "    \"PaCO2\": [778,220235,50818],\n",
    "    \"PaO2\": [779,220224,50821],\n",
    "    \"pH\": [780,1126,4753,223830],\n",
    "    \"Platelets\": [51265],\n",
    "    \"RespRate\": [618, 615, 220210, 224690],\n",
    "    \"SaO2\": [834, 220227],\n",
    "    \"SysABP\": [51,6701,220050],\n",
    "    \"Temp\": [676, 223762],\n",
    "    \"TropI\": [51002],\n",
    "    \"TropT\": [51003],\n",
    "    \"Urine\": [40055, 226559],\n",
    "    \"WBC\": [51301],\n",
    "    \"Weight\": [763, 224639],\n",
    "    \"Mech\": [651],\n",
    "}\n",
    "selected_itemid = []\n",
    "for k,v in mapping_dict.items():\n",
    "    selected_itemid.extend(v)\n",
    "\n",
    "time_features = list(mapping_dict.keys())\n",
    "    \n",
    "len(selected_itemid),len(mapping_dict),time_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_range = {\n",
    "     'Albumin': {'min': 0, 'max': 6},\n",
    "     'ALP': {'min': 0, 'max': 5000},\n",
    "     'ALT': {'min': 0, 'max': 25000},\n",
    "     'AST': {'min': 0, 'max': 40000},\n",
    "     'Bilirubin': {'min': 0, 'max': 100},\n",
    "     'BUN': {'min': 0, 'max': 250},\n",
    "     'Cholesterol': {'min': 0, 'max': 800},\n",
    "     'Creatinine': {'min': 0, 'max': 25},\n",
    "     'DiasABP': {'min': 0, 'max': 300},\n",
    "     'FiO2': {'min': 0, 'max': 100},\n",
    "     'GCS': {'min': 3, 'max': 15},\n",
    "     'Glucose': {'min': 0, 'max': 1600},\n",
    "     'HCO3': {'min': 0, 'max': 60},\n",
    "     'HCT': {'min': 0, 'max': 70},\n",
    "     'HR': {'min': 0, 'max': 350},\n",
    "     'K': {'min': 0, 'max': 30},\n",
    "     'Lactate': {'min': 0, 'max': 40},\n",
    "     'Mg': {'min': 0, 'max': 40},\n",
    "     'MAP': {'min': 0, 'max': 375},\n",
    "     'Na': {'min': 0, 'max': 200},\n",
    "     'NIDiasABP': {'min': 0, 'max': 300}, # !!!\n",
    "     'NIMAP': {'min': 0, 'max': 300},\n",
    "     'NISysABP': {'min': 0, 'max': 300},\n",
    "     'PaCO2': {'min': 0, 'max': 200},\n",
    "     'PaO2': {'min': 0, 'max': 800},\n",
    "     'pH': {'min': 6, 'max': 8},\n",
    "     'Platelets': {'min': 0, 'max': 2500},\n",
    "     'RespRate': {'min': 0, 'max': 100},\n",
    "     'SaO2': {'min': 0, 'max': 100},\n",
    "     'SysABP': {'min': 0, 'max': 300},\n",
    "     'Temp': {'min': 15, 'max': 47},\n",
    "     'TropI': {'min': 0, 'max': 50},\n",
    "     'TropT': {'min': 0, 'max': 30},\n",
    "     'Urine': {'min': 0, 'max': 3000},\n",
    "     'WBC': {'min': 0, 'max': 550},\n",
    "     'Weight': {'min': 20, 'max': 300}, # !!!\n",
    "     'Mech': {'min': 0, 'max': 100}\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{50862: 0,\n",
       " 50863: 1,\n",
       " 50861: 2,\n",
       " 50878: 3,\n",
       " 50885: 4,\n",
       " 51006: 5,\n",
       " 50907: 6,\n",
       " 50912: 7,\n",
       " 8368: 8,\n",
       " 8555: 8,\n",
       " 220051: 8,\n",
       " 2981: 9,\n",
       " 3420: 9,\n",
       " 3422: 9,\n",
       " 223835: 9,\n",
       " 198: 10,\n",
       " 223901: 10,\n",
       " 223900: 10,\n",
       " 220739: 10,\n",
       " 807: 11,\n",
       " 811: 11,\n",
       " 1529: 11,\n",
       " 3745: 11,\n",
       " 3744: 11,\n",
       " 225664: 11,\n",
       " 220621: 11,\n",
       " 226537: 11,\n",
       " 50809: 11,\n",
       " 50931: 11,\n",
       " 50882: 12,\n",
       " 51221: 13,\n",
       " 211: 14,\n",
       " 220045: 14,\n",
       " 50971: 15,\n",
       " 50813: 16,\n",
       " 50960: 17,\n",
       " 52: 18,\n",
       " 6702: 18,\n",
       " 220052: 18,\n",
       " 50983: 19,\n",
       " 8441: 20,\n",
       " 220180: 20,\n",
       " 456: 21,\n",
       " 220181: 21,\n",
       " 455: 22,\n",
       " 220179: 22,\n",
       " 778: 23,\n",
       " 220235: 23,\n",
       " 50818: 23,\n",
       " 779: 24,\n",
       " 220224: 24,\n",
       " 50821: 24,\n",
       " 780: 25,\n",
       " 1126: 25,\n",
       " 4753: 25,\n",
       " 223830: 25,\n",
       " 51265: 26,\n",
       " 618: 27,\n",
       " 615: 27,\n",
       " 220210: 27,\n",
       " 224690: 27,\n",
       " 834: 28,\n",
       " 220227: 28,\n",
       " 51: 29,\n",
       " 6701: 29,\n",
       " 220050: 29,\n",
       " 676: 30,\n",
       " 223762: 30,\n",
       " 51002: 31,\n",
       " 51003: 32,\n",
       " 40055: 33,\n",
       " 226559: 33,\n",
       " 51301: 34,\n",
       " 763: 35,\n",
       " 224639: 35,\n",
       " 651: 36}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_mapping_dict = {}\n",
    "count = 0\n",
    "for k,v in mapping_dict.items():\n",
    "    for i in v:\n",
    "        re_mapping_dict[i] = count\n",
    "    count+=1\n",
    "re_mapping_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['preprocess_MIMIC3.ipynb', 'data', 'mimic3-benchmarks', '.ipynb_checkpoints']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', 'PRESCRIPTIONS.csv', 'D_ICD_DIAGNOSES.csv', 'D_ICD_PROCEDURES.csv', 'CHARTEVENTS.csv', 'SERVICES.csv', 'PROCEDURES_ICD.csv', 'PATIENTS.csv', 'MICROBIOLOGYEVENTS.csv', 'ADMISSIONS.csv', 'CALLOUT.csv', 'CAREGIVERS.csv', 'robots.txt.tmp', 'TRANSFERS.csv', 'D_CPT.csv', 'NOTEEVENTS.csv', 'DATETIMEEVENTS.csv', 'ICUSTAYS.csv', 'DRGCODES.csv', 'LABEVENTS.csv', 'CPTEVENTS.csv', 'DIAGNOSES_ICD.csv', 'D_ITEMS.csv', 'D_LABITEMS.csv', 'PROCEDUREEVENTS_MV.csv', 'OUTPUTEVENTS.csv', 'INPUTEVENTS_MV.csv', 'INPUTEVENTS_CV.csv']\n"
     ]
    }
   ],
   "source": [
    "mimic3_path = \"xxxxx/MIMIC_III/full_data/\"\n",
    "file_path = \"xxxxx/MIMIC_III/mimic3-benchmarks/data/\"\n",
    "data_path = \"./data/\"\n",
    "if not os.path.exists(data_path):\n",
    "    os.mkdir(data_path)\n",
    "if not os.path.exists(mimic3_path):\n",
    "    raise FileNotFoundError(\"MIMIC3 csv data not founded in: %s\", mimic3_path)\n",
    "else:\n",
    "    print(os.listdir(mimic3_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index = list(os.listdir(file_path + \"/train/\"))\n",
    "test_index = list(os.listdir(file_path + \"/test/\"))\n",
    "\n",
    "patient_files = []\n",
    "for sub_index in train_index:\n",
    "    patient_files.append([\"xxxxx/MIMIC_III/mimic3-benchmarks/data/train/\",sub_index])\n",
    "for sub_index in test_index:\n",
    "    patient_files.append([\"xxxxx/MIMIC_III/mimic3-benchmarks/data/test/\",sub_index])\n",
    "len(patient_files), patient_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stays.csv',\n",
       " 'diagnoses.csv',\n",
       " 'episode3.csv',\n",
       " 'episode3_timeseries.csv',\n",
       " 'episode2_timeseries.csv',\n",
       " 'events.csv',\n",
       " 'episode2.csv']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_path = patient_files[1][0]+patient_files[1][1] + \"/\"\n",
    "os.listdir(exp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 182917, Timestamp('2125-08-03 07:35:27'), [0, 0, 0, 4.1627, 10.274]],\n",
       " [2, 188422, Timestamp('2125-08-25 12:06:45'), [0, 0, 0, 13.0287, 20.1828]]]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_stay(exp_path):\n",
    "    exp_stays = pd.read_csv(exp_path+\"/stays.csv\")\n",
    "    exp_stays['INTIME'] = pd.to_datetime(exp_stays['INTIME'])\n",
    "    exp_stays['DISCHTIME'] = pd.to_datetime(exp_stays['DISCHTIME'])\n",
    "    exp_stays['LOS2'] = round((exp_stays['DISCHTIME']-exp_stays['INTIME'])/datetime.timedelta(days=1),4)\n",
    "    out_stay = []\n",
    "    for index,row in exp_stays.iterrows():\n",
    "        if row.LOS < 2 or np.isnan(row.LOS):\n",
    "            continue            \n",
    "        out_stay.append([index, row.HADM_ID,row.INTIME, [row.MORTALITY_INUNIT,row.MORTALITY_INHOSPITAL,row.MORTALITY,row.LOS,row.LOS2]])\n",
    "    return out_stay\n",
    "\n",
    "exp_stays = load_stay(exp_path)\n",
    "exp_stays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>ICUSTAY_ID</th>\n",
       "      <th>CHARTTIME</th>\n",
       "      <th>ITEMID</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>VALUEUOM</th>\n",
       "      <th>CHECK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1050</td>\n",
       "      <td>182917</td>\n",
       "      <td>229166</td>\n",
       "      <td>2125-08-03 12:00:00</td>\n",
       "      <td>52</td>\n",
       "      <td>70</td>\n",
       "      <td>mmHg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1050</td>\n",
       "      <td>182917</td>\n",
       "      <td>229166</td>\n",
       "      <td>2125-08-03 12:00:00</td>\n",
       "      <td>55</td>\n",
       "      <td>84</td>\n",
       "      <td>mmHg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1050</td>\n",
       "      <td>182917</td>\n",
       "      <td>229166</td>\n",
       "      <td>2125-08-03 12:00:00</td>\n",
       "      <td>59</td>\n",
       "      <td>101</td>\n",
       "      <td>mmHg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1050</td>\n",
       "      <td>182917</td>\n",
       "      <td>229166</td>\n",
       "      <td>2125-08-03 12:00:00</td>\n",
       "      <td>62</td>\n",
       "      <td>52</td>\n",
       "      <td>mmHg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1050</td>\n",
       "      <td>182917</td>\n",
       "      <td>229166</td>\n",
       "      <td>2125-08-03 12:00:00</td>\n",
       "      <td>211</td>\n",
       "      <td>77</td>\n",
       "      <td>BPM</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17982</th>\n",
       "      <td>1050</td>\n",
       "      <td>182917</td>\n",
       "      <td>229166</td>\n",
       "      <td>2125-08-05 23:00:00</td>\n",
       "      <td>40069</td>\n",
       "      <td>200</td>\n",
       "      <td>ml</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17983</th>\n",
       "      <td>1050</td>\n",
       "      <td>188422</td>\n",
       "      <td>248879</td>\n",
       "      <td>2125-08-25 19:00:00</td>\n",
       "      <td>40055</td>\n",
       "      <td>35</td>\n",
       "      <td>ml</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17984</th>\n",
       "      <td>1050</td>\n",
       "      <td>188422</td>\n",
       "      <td>248879</td>\n",
       "      <td>2125-08-29 08:00:00</td>\n",
       "      <td>40060</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17985</th>\n",
       "      <td>1050</td>\n",
       "      <td>188422</td>\n",
       "      <td>248879</td>\n",
       "      <td>2125-08-26 10:00:00</td>\n",
       "      <td>40055</td>\n",
       "      <td>45</td>\n",
       "      <td>ml</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17986</th>\n",
       "      <td>1050</td>\n",
       "      <td>188422</td>\n",
       "      <td>248879</td>\n",
       "      <td>2125-08-26 20:00:00</td>\n",
       "      <td>40055</td>\n",
       "      <td>80</td>\n",
       "      <td>ml</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10362 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SUBJECT_ID  HADM_ID  ICUSTAY_ID           CHARTTIME  ITEMID VALUE  \\\n",
       "4            1050   182917      229166 2125-08-03 12:00:00      52    70   \n",
       "5            1050   182917      229166 2125-08-03 12:00:00      55    84   \n",
       "6            1050   182917      229166 2125-08-03 12:00:00      59   101   \n",
       "7            1050   182917      229166 2125-08-03 12:00:00      62    52   \n",
       "17           1050   182917      229166 2125-08-03 12:00:00     211    77   \n",
       "...           ...      ...         ...                 ...     ...   ...   \n",
       "17982        1050   182917      229166 2125-08-05 23:00:00   40069   200   \n",
       "17983        1050   188422      248879 2125-08-25 19:00:00   40055    35   \n",
       "17984        1050   188422      248879 2125-08-29 08:00:00   40060     0   \n",
       "17985        1050   188422      248879 2125-08-26 10:00:00   40055    45   \n",
       "17986        1050   188422      248879 2125-08-26 20:00:00   40055    80   \n",
       "\n",
       "      VALUEUOM  CHECK  \n",
       "4         mmHg   True  \n",
       "5         mmHg   True  \n",
       "6         mmHg   True  \n",
       "7         mmHg   True  \n",
       "17         BPM   True  \n",
       "...        ...    ...  \n",
       "17982       ml   True  \n",
       "17983       ml   True  \n",
       "17984      NaN   True  \n",
       "17985       ml   True  \n",
       "17986       ml   True  \n",
       "\n",
       "[10362 rows x 8 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_numerical(df,col_name):\n",
    "    df['CHECK'] = df.VALUE.apply(lambda x:str(x).replace(\".\",'',1).isdigit())\n",
    "    return df\n",
    "\n",
    "def transfer_gcs(df):\n",
    "#     print(len(df[(df.ITEMID == 223901) | (df.ITEMID == 223900) | (df.ITEMID == 220739)]))\n",
    "#     df.CHARTTIME = pd.to_datetime(df.CHARTTIME)\n",
    "#     print(df[(df.ITEMID == 223901) | (df.ITEMID == 223900) | (df.ITEMID == 220739)].sort_values(\"CHARTTIME\")[:10])\n",
    "    df.VALUE = df.apply(lambda row: GCS_eye[row.VALUE] if row.ITEMID == 220739 else row.VALUE,axis=1)\n",
    "    df.VALUE = df.apply(lambda row: GCS_motor[row.VALUE] if row.ITEMID == 223901 else row.VALUE,axis=1)\n",
    "    df.VALUE = df.apply(lambda row: GCS_verbal[row.VALUE] if row.ITEMID == 223900 else row.VALUE,axis=1)\n",
    "    return df\n",
    "\n",
    "def load_event(exp_path):\n",
    "    exp_events = pd.read_csv(exp_path+\"/events.csv\")\n",
    "    exp_events.CHARTTIME = pd.to_datetime(exp_events.CHARTTIME)\n",
    "    exp_events = exp_events[~exp_events.VALUE.isnull()]\n",
    "    exp_events = transfer_gcs(exp_events)\n",
    "    exp_events = is_numerical(exp_events,'VALUE')\n",
    "    return exp_events[exp_events.CHECK]# .drop(['CHECK'],1)\n",
    "\n",
    "exp_events = load_event(exp_path)\n",
    "exp_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 182917, Timestamp('2125-08-03 07:35:27')]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>ICUSTAY_ID</th>\n",
       "      <th>CHARTTIME</th>\n",
       "      <th>ITEMID</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>VALUEUOM</th>\n",
       "      <th>CHECK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9589</th>\n",
       "      <td>1050</td>\n",
       "      <td>182917</td>\n",
       "      <td>229166</td>\n",
       "      <td>0.909167</td>\n",
       "      <td>742</td>\n",
       "      <td>1</td>\n",
       "      <td>kg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14260</th>\n",
       "      <td>1050</td>\n",
       "      <td>182917</td>\n",
       "      <td>229166</td>\n",
       "      <td>0.909167</td>\n",
       "      <td>8547</td>\n",
       "      <td>160</td>\n",
       "      <td>mmHg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14262</th>\n",
       "      <td>1050</td>\n",
       "      <td>182917</td>\n",
       "      <td>229166</td>\n",
       "      <td>0.909167</td>\n",
       "      <td>8551</td>\n",
       "      <td>165</td>\n",
       "      <td>mmHg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14263</th>\n",
       "      <td>1050</td>\n",
       "      <td>182917</td>\n",
       "      <td>229166</td>\n",
       "      <td>0.909167</td>\n",
       "      <td>8552</td>\n",
       "      <td>20</td>\n",
       "      <td>mmHg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14264</th>\n",
       "      <td>1050</td>\n",
       "      <td>182917</td>\n",
       "      <td>229166</td>\n",
       "      <td>0.909167</td>\n",
       "      <td>8553</td>\n",
       "      <td>30</td>\n",
       "      <td>BPM</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10967</th>\n",
       "      <td>1050</td>\n",
       "      <td>182917</td>\n",
       "      <td>229166</td>\n",
       "      <td>47.409167</td>\n",
       "      <td>5819</td>\n",
       "      <td>8</td>\n",
       "      <td>BPM</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10968</th>\n",
       "      <td>1050</td>\n",
       "      <td>182917</td>\n",
       "      <td>229166</td>\n",
       "      <td>47.409167</td>\n",
       "      <td>5820</td>\n",
       "      <td>92</td>\n",
       "      <td>%</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>1050</td>\n",
       "      <td>182917</td>\n",
       "      <td>229166</td>\n",
       "      <td>47.409167</td>\n",
       "      <td>211</td>\n",
       "      <td>96</td>\n",
       "      <td>BPM</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>1050</td>\n",
       "      <td>182917</td>\n",
       "      <td>229166</td>\n",
       "      <td>47.409167</td>\n",
       "      <td>456</td>\n",
       "      <td>63</td>\n",
       "      <td>mmHg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>1050</td>\n",
       "      <td>182917</td>\n",
       "      <td>229166</td>\n",
       "      <td>47.409167</td>\n",
       "      <td>491</td>\n",
       "      <td>40</td>\n",
       "      <td>mmHg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1316 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SUBJECT_ID  HADM_ID  ICUSTAY_ID  CHARTTIME  ITEMID VALUE VALUEUOM  \\\n",
       "9589         1050   182917      229166   0.909167     742     1       kg   \n",
       "14260        1050   182917      229166   0.909167    8547   160     mmHg   \n",
       "14262        1050   182917      229166   0.909167    8551   165     mmHg   \n",
       "14263        1050   182917      229166   0.909167    8552    20     mmHg   \n",
       "14264        1050   182917      229166   0.909167    8553    30      BPM   \n",
       "...           ...      ...         ...        ...     ...   ...      ...   \n",
       "10967        1050   182917      229166  47.409167    5819     8      BPM   \n",
       "10968        1050   182917      229166  47.409167    5820    92        %   \n",
       "1090         1050   182917      229166  47.409167     211    96      BPM   \n",
       "1098         1050   182917      229166  47.409167     456    63     mmHg   \n",
       "1103         1050   182917      229166  47.409167     491    40     mmHg   \n",
       "\n",
       "       CHECK  \n",
       "9589    True  \n",
       "14260   True  \n",
       "14262   True  \n",
       "14263   True  \n",
       "14264   True  \n",
       "...      ...  \n",
       "10967   True  \n",
       "10968   True  \n",
       "1090    True  \n",
       "1098    True  \n",
       "1103    True  \n",
       "\n",
       "[1316 rows x 8 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def divide_event_by_stay(event,adm_id,intime):\n",
    "    event = event[event.HADM_ID == adm_id]\n",
    "    event.CHARTTIME = (event.CHARTTIME - intime) / datetime.timedelta(hours=1)\n",
    "    event = event.sort_values(\"CHARTTIME\")\n",
    "    event = admission_in_hours(event,\"CHARTTIME\",48)\n",
    "    return event\n",
    "\n",
    "def admission_in_hours(df,col_name,hours=48):\n",
    "    df = df[(df[col_name]>=0)&(df[col_name]<48)]\n",
    "    return df\n",
    "\n",
    "for admission in exp_stays:\n",
    "    print(admission)\n",
    "    exp_out_events = divide_event_by_stay(exp_events,admission[1],admission[2])\n",
    "    break\n",
    "    \n",
    "exp_out_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 182917, Timestamp('2125-08-03 07:35:27'), [0, 0, 0, 4.1627, 10.274]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([-1.        , -1.        , -1.        , -1.        ,  1.        ,\n",
       "        -1.        , -1.        ,  1.        , -1.        , 84.93785283,\n",
       "        -1.        , -1.        ]),\n",
       " array([1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_episode_info(exp_path, e_index):\n",
    "    # print(os.listdir(exp_path))\n",
    "    if not os.path.exists(exp_path+\"/episode%d.csv\"%e_index):\n",
    "        return []\n",
    "    raw_info = pd.read_csv(exp_path+\"/episode%d.csv\"%e_index)\n",
    "    raw_info = np.array(raw_info)[0]\n",
    "    info = np.full(12,-1.0)\n",
    "    info[int(raw_info[1])] = 1\n",
    "    info[5 + int(raw_info[2])] = 1\n",
    "    for index in range(3,6):\n",
    "        if not np.isnan(raw_info[index]):\n",
    "            info[9+index-3]=raw_info[index]\n",
    "    diag = np.array(raw_info[8:], dtype=np.int)\n",
    "    return info, diag\n",
    "\n",
    "for admission in exp_stays:\n",
    "    print(admission)\n",
    "    exp_infos = get_episode_info(exp_path,admission[0]+1)\n",
    "    break\n",
    "exp_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'stime': [0,\n",
       "   3600,\n",
       "   7200,\n",
       "   10800,\n",
       "   14400,\n",
       "   18000,\n",
       "   21600,\n",
       "   25200,\n",
       "   28800,\n",
       "   32400,\n",
       "   36000,\n",
       "   39600,\n",
       "   43200,\n",
       "   46800,\n",
       "   50400,\n",
       "   54000,\n",
       "   57600,\n",
       "   61200,\n",
       "   64800,\n",
       "   68400,\n",
       "   72000,\n",
       "   75600,\n",
       "   79200,\n",
       "   82800,\n",
       "   86400,\n",
       "   90000,\n",
       "   93600,\n",
       "   97200,\n",
       "   100800,\n",
       "   104400,\n",
       "   108000,\n",
       "   111600,\n",
       "   115200,\n",
       "   118800,\n",
       "   122400,\n",
       "   126000,\n",
       "   129600,\n",
       "   133200,\n",
       "   136800,\n",
       "   140400,\n",
       "   144000,\n",
       "   147600,\n",
       "   151200,\n",
       "   154800,\n",
       "   158400,\n",
       "   162000,\n",
       "   165600,\n",
       "   169200],\n",
       "  'tdata': array([[ 0. ,  0. ,  0. , ...,  0. ,  0. ,  0. ],\n",
       "         [ 0. , 95. , 53. , ..., 16.4,  0. ,  0. ],\n",
       "         [ 0. ,  0. ,  0. , ...,  0. ,  0. ,  0. ],\n",
       "         ...,\n",
       "         [ 0. ,  0. ,  0. , ...,  0. ,  0. ,  0. ],\n",
       "         [ 0. ,  0. ,  0. , ...,  0. ,  0. ,  0. ],\n",
       "         [ 0. ,  0. ,  0. , ...,  0. ,  0. ,  0. ]]),\n",
       "  'tmask': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 1., 1., ..., 1., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]])},\n",
       " {'stime': [0.9091666666666667,\n",
       "   1.4091666666666667,\n",
       "   1.9091666666666667,\n",
       "   2.4091666666666667,\n",
       "   3.4091666666666667,\n",
       "   3.9091666666666667,\n",
       "   4.409166666666667,\n",
       "   5.409166666666667,\n",
       "   6.409166666666667,\n",
       "   7.409166666666667,\n",
       "   8.409166666666666,\n",
       "   9.409166666666666,\n",
       "   10.159166666666666,\n",
       "   11.409166666666666,\n",
       "   12.909166666666666,\n",
       "   13.409166666666666,\n",
       "   14.409166666666666,\n",
       "   16.409166666666668,\n",
       "   18.409166666666668,\n",
       "   18.909166666666668,\n",
       "   19.409166666666668,\n",
       "   21.409166666666668,\n",
       "   22.409166666666668,\n",
       "   23.159166666666668,\n",
       "   23.409166666666668,\n",
       "   24.409166666666668,\n",
       "   24.909166666666668,\n",
       "   25.409166666666668,\n",
       "   26.409166666666668,\n",
       "   27.409166666666668,\n",
       "   28.409166666666668,\n",
       "   28.8925,\n",
       "   29.409166666666668,\n",
       "   30.409166666666668,\n",
       "   31.409166666666668,\n",
       "   31.909166666666668,\n",
       "   32.409166666666664,\n",
       "   32.909166666666664,\n",
       "   33.409166666666664,\n",
       "   34.409166666666664,\n",
       "   35.409166666666664,\n",
       "   36.409166666666664,\n",
       "   37.409166666666664,\n",
       "   38.409166666666664,\n",
       "   40.409166666666664,\n",
       "   42.409166666666664,\n",
       "   42.85916666666667,\n",
       "   44.409166666666664,\n",
       "   45.409166666666664,\n",
       "   46.409166666666664,\n",
       "   47.409166666666664],\n",
       "  'tdata': array([[ 0. ,  0. ,  0. , ...,  0. ,  0. ,  0. ],\n",
       "         [ 0. , 95. , 53. , ..., 16.4,  0. ,  0. ],\n",
       "         [ 0. ,  0. ,  0. , ...,  0. ,  0. ,  0. ],\n",
       "         ...,\n",
       "         [ 0. ,  0. ,  0. , ...,  0. ,  0. ,  0. ],\n",
       "         [ 0. ,  0. ,  0. , ...,  0. ,  0. ,  0. ],\n",
       "         [ 0. ,  0. ,  0. , ...,  0. ,  0. ,  0. ]]),\n",
       "  'tmask': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 1, 1, ..., 1, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]])}]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# col_name = [\"Hour\"] + list(mapping_dict.keys())\n",
    "def generate_sample(adm_events):\n",
    "    adm_events = adm_events[adm_events.ITEMID.isin(selected_itemid)]\n",
    "    \n",
    "    sample_re_stime = [3600*i for i in range(48)]\n",
    "    sample_re_tdata = np.full((48,len(time_features)),0.0)\n",
    "    sample_re_tmask = np.full((48,len(time_features)),0.0)\n",
    "    \n",
    "    sample_ir_stime = list(set(adm_events.CHARTTIME))\n",
    "    sample_ir_stime.sort()\n",
    "    sample_ir_tdata = []\n",
    "    sample_ir_tmask = []\n",
    "    \n",
    "    for t in sample_ir_stime:\n",
    "        sub_data = np.full(len(time_features), 0.0)\n",
    "        sub_mask = np.full(len(time_features), 0)\n",
    "        sub_events = adm_events[adm_events.CHARTTIME==t]\n",
    "        t_hour = int(t)\n",
    "        for index,row in sub_events.iterrows():\n",
    "            f_index = re_mapping_dict[row.ITEMID]\n",
    "            feature_name = time_features[f_index]\n",
    "            min_feature = valid_range[feature_name][\"min\"]\n",
    "            max_feature = valid_range[feature_name][\"max\"]\n",
    "            \n",
    "            if float(row.VALUE)>=min_feature and float(row.VALUE)<=max_feature:    \n",
    "                if f_index == 11: # GCS\n",
    "                    if sub_data[f_index]==0.0:\n",
    "                        sub_data[f_index] = float(row.VALUE)\n",
    "                        sub_mask[f_index] = 1\n",
    "                        sample_re_tdata[t_hour, f_index]=float(row.VALUE)\n",
    "                        sample_re_tmask[t_hour, f_index]=1\n",
    "                    else:\n",
    "                        sub_data[f_index] += float(row.VALUE)\n",
    "                        sample_re_tdata[t_hour, f_index]=float(row.VALUE)\n",
    "                else:   \n",
    "                    sub_data[f_index] = float(row.VALUE)\n",
    "                    sub_mask[f_index] = 1\n",
    "                    sample_re_tdata[t_hour, f_index]=float(row.VALUE)\n",
    "                    sample_re_tmask[t_hour, f_index]=1\n",
    "        sample_ir_tdata.append(sub_data)\n",
    "        sample_ir_tmask.append(sub_mask)\n",
    "    \n",
    "    \n",
    "    return [{\n",
    "                 \"stime\": sample_re_stime,\n",
    "                 \"tdata\": sample_re_tdata,\n",
    "                 \"tmask\": sample_re_tmask,\n",
    "             },\n",
    "             {\n",
    "                 \"stime\": sample_ir_stime,\n",
    "                 \"tdata\": np.array(sample_ir_tdata),\n",
    "                 \"tmask\": np.array(sample_ir_tmask),\n",
    "             }]\n",
    "\n",
    "tem = generate_sample(exp_out_events)\n",
    "tem # , np.sum(~np.isnan(tem),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no event after division  14761 155581 2193-05-31 04:57:00\n",
      "no event after division  14761 107155 2193-07-11 21:17:00\n",
      "no event after division  5772 133327 2163-07-30 23:05:00\n",
      "no event after division  16881 166063 2164-08-17 14:10:00\n",
      "no event after division  23761 111184 2187-09-08 21:27:00\n",
      "no event after division  24552 124040 2152-12-08 06:17:00\n",
      "no event after division  4264 147554 2107-07-10 14:07:00\n",
      "no event after division  2592 130856 2183-06-05 21:03:00\n",
      "no event after division  5259 195496 2144-03-08 16:38:00\n",
      "no event after division  23946 197173 2148-07-01 19:05:00\n",
      "no event after division  29280 134662 2159-07-30 13:19:00\n",
      "no event after division  2322 169179 2176-03-14 09:25:00\n",
      "no event after division  87428 116173 2118-01-15 11:43:00\n",
      "no event after division  9736 106592 2184-06-06 09:59:00\n",
      "no event after division  7534 194035 2160-05-18 17:44:00\n",
      "no event after division  30610 180378 2165-05-07 02:27:00\n",
      "no event after division  25115 153867 2198-05-03 15:28:00\n",
      "no event after division  10446 147753 2158-03-23 19:25:00\n",
      "no event after division  12564 129578 2143-07-12 10:20:00\n",
      "no event after division  17655 166996 2189-05-25 18:05:00\n",
      "no event after division  24858 164274 2177-02-20 22:33:00\n",
      "no event after division  9540 154945 2201-04-28 12:59:00\n",
      "no event after division  15017 154199 2152-03-16 07:21:00\n",
      "no event after division  15017 158074 2152-04-10 15:27:00\n",
      "no event after division  25787 180521 2145-03-25 23:41:00\n",
      "no event after division  9976 119958 2193-03-28 04:26:00\n",
      "no event after division  55357 119355 2187-06-08 02:27:00\n",
      "no event after division  13355 187308 2157-08-01 14:26:00\n",
      "no event after division  15374 165280 2133-04-30 20:12:00\n",
      "no event after division  5077 108056 2138-03-13 18:05:00\n",
      "no event after division  71054 146124 2166-07-23 07:57:00\n",
      "no event after division  20409 102314 2119-02-16 10:09:00\n",
      "no event after division  863 137310 2117-06-21 14:35:00\n",
      "no event after division  8267 181624 2162-04-08 23:17:00\n",
      "no event after division  13192 175809 2145-05-30 00:09:00\n",
      "no event after division  21274 175983 2181-12-06 20:05:00\n",
      "no event after division  26200 162822 2180-05-10 19:36:00\n",
      "no event after division  3084 152571 2122-06-07 13:03:00\n",
      "no event after division  17722 168945 2154-04-23 00:38:00\n",
      "no event after division  74835 105494 2194-01-22 15:06:00\n",
      "no event after division  7546 147476 2188-03-18 12:33:00\n",
      "no event after division  7546 158207 2188-04-01 22:22:00\n",
      "no event after division  7275 145466 2131-08-15 09:47:00\n",
      "no event after division  13728 171866 2149-06-02 14:51:00\n",
      "no event after division  5637 157276 2194-03-18 14:06:00\n",
      "no event after division  948 107027 2107-05-26 10:40:00\n",
      "no event after division  19191 146945 2199-08-02 10:29:00\n",
      "no event after division  24307 127499 2143-02-25 09:35:00\n",
      "no event after division  19102 160558 2135-07-06 02:02:00\n",
      "no event after division  18350 165230 2121-07-07 13:42:00\n",
      "no event after division  4454 177326 2183-07-15 01:10:00\n",
      "no event after division  4454 134657 2183-08-18 06:43:00\n",
      "no event after division  19823 179754 2167-02-17 17:47:00\n",
      "no event after division  23179 184235 2158-03-20 15:47:00\n",
      "no event after division  24116 133881 2137-05-25 08:07:00\n",
      "no event after division  8471 108550 2114-02-23 22:25:00\n",
      "no event after division  9032 158822 2175-09-04 23:06:00\n",
      "no event after division  17548 133671 2180-01-20 06:45:00\n",
      "no event after division  26187 151965 2119-01-24 19:29:00\n",
      "no event after division  323 192631 2115-05-20 10:41:00\n",
      "no event after division  7671 160689 2196-06-29 20:31:00\n",
      "no event after division  19097 102038 2185-07-21 15:31:00\n",
      "no event after division  16053 189195 2112-04-20 19:34:00\n",
      "no event after division  14469 155925 2111-06-10 14:31:00\n",
      "no event after division  11338 109986 2122-07-12 12:51:00\n",
      "no event after division  6604 140493 2111-08-28 19:07:00\n",
      "no event after division  19872 134153 2106-08-10 07:30:00\n",
      "no event after division  10774 119905 2133-05-26 10:52:00\n",
      "no event after division  20979 107010 2168-08-11 05:35:00\n",
      "no event after division  25400 197907 2142-05-06 04:34:00\n",
      "no event after division  14219 171956 2138-05-14 16:19:51\n",
      "no event after division  23275 158761 2179-07-27 04:05:00\n",
      "no event after division  5158 191320 2162-04-29 12:05:00\n",
      "no event after division  16013 174375 2129-06-10 23:06:00\n",
      "no event after division  16013 196057 2129-06-30 09:26:00\n",
      "no event after division  24263 103624 2160-04-28 00:42:00\n",
      "no event after division  18738 147642 2164-03-07 17:38:00\n",
      "no event after division  15333 122137 2196-03-14 16:42:00\n",
      "no event after division  13494 164195 2141-03-24 12:12:00\n",
      "no event after division  16994 115444 2111-06-09 10:48:00\n",
      "no event after division  16994 172866 2111-07-13 13:04:00\n",
      "no event after division  21280 151543 2157-01-12 07:39:00\n",
      "no event after division  13316 172688 2104-02-12 00:24:00\n",
      "no event after division  94828 132498 2101-12-30 12:46:00\n",
      "no event after division  14031 185677 2172-02-19 23:04:00\n",
      "no event after division  25216 187104 2111-08-13 16:31:00\n",
      "no event after division  24248 162716 2157-12-15 00:45:00\n",
      "no event after division  24248 109789 2158-05-30 21:54:00\n",
      "no event after division  7155 155887 2175-01-13 11:45:00\n",
      "no event after division  6702 132390 2123-04-28 17:39:00\n",
      "no event after division  16178 138464 2143-02-15 00:54:00\n",
      "no event after division  12411 173718 2183-03-12 01:00:00\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for file in track(patient_files):\n",
    "    # print(os.listdir(file[0]+file[1]))\n",
    "    exp_stays = load_stay(file[0]+file[1])\n",
    "    if len(exp_stays) == 0 :\n",
    "        # print(\"no valid stay \",file[1])\n",
    "        continue\n",
    "    exp_events = load_event(file[0]+file[1])\n",
    "    if len(exp_events)==0:\n",
    "        # print(\"no valid event \",file[1])\n",
    "        continue\n",
    "\n",
    "    for admission in exp_stays:\n",
    "        # print(admission)\n",
    "        count +=1\n",
    "        adm_data = divide_event_by_stay(exp_events,admission[1],admission[2])\n",
    "        if len(adm_data) == 0:\n",
    "            print(\"no event after division \",file[1],admission[1], admission[2])\n",
    "            continue\n",
    "        exp_infos = get_episode_info(file[0]+file[1], admission[0]+1)\n",
    "        if exp_infos == []:\n",
    "            print(\"no info and diag \",file[1],admission[0]+1, admission[2])\n",
    "            continue\n",
    "        adm_data = generate_sample(adm_data)\n",
    "        \n",
    "        np.savez(data_path+\"%s_episode%d\"%(file[1],admission[0]),\n",
    "                 info = exp_infos[0],\n",
    "                 diag = exp_infos[1],\n",
    "                 regular_data = adm_data[0],\n",
    "                 irregular_data = adm_data[1],\n",
    "                 labels = admission[3],\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['info', 'diag', 'regular_data', 'irregular_data', 'labels']\n",
      "[-1.         -1.         -1.         -1.          1.         -1.\n",
      " -1.          1.         -1.         84.93785283 -1.         -1.        ]\n",
      "[1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "{'stime': [0, 3600, 7200, 10800, 14400, 18000, 21600, 25200, 28800, 32400, 36000, 39600, 43200, 46800, 50400, 54000, 57600, 61200, 64800, 68400, 72000, 75600, 79200, 82800, 86400, 90000, 93600, 97200, 100800, 104400, 108000, 111600, 115200, 118800, 122400, 126000, 129600, 133200, 136800, 140400, 144000, 147600, 151200, 154800, 158400, 162000, 165600, 169200], 'tdata': array([[ 0. ,  0. ,  0. , ...,  0. ,  0. ,  0. ],\n",
      "       [ 0. , 95. , 53. , ..., 16.4,  0. ,  0. ],\n",
      "       [ 0. ,  0. ,  0. , ...,  0. ,  0. ,  0. ],\n",
      "       ...,\n",
      "       [ 0. ,  0. ,  0. , ...,  0. ,  0. ,  0. ],\n",
      "       [ 0. ,  0. ,  0. , ...,  0. ,  0. ,  0. ],\n",
      "       [ 0. ,  0. ,  0. , ...,  0. ,  0. ,  0. ]]), 'tmask': array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 1., 1., ..., 1., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]])}\n",
      "{'stime': [0.9091666666666667, 1.4091666666666667, 1.9091666666666667, 2.4091666666666667, 3.4091666666666667, 3.9091666666666667, 4.409166666666667, 5.409166666666667, 6.409166666666667, 7.409166666666667, 8.409166666666666, 9.409166666666666, 10.159166666666666, 11.409166666666666, 12.909166666666666, 13.409166666666666, 14.409166666666666, 16.409166666666668, 18.409166666666668, 18.909166666666668, 19.409166666666668, 21.409166666666668, 22.409166666666668, 23.159166666666668, 23.409166666666668, 24.409166666666668, 24.909166666666668, 25.409166666666668, 26.409166666666668, 27.409166666666668, 28.409166666666668, 28.8925, 29.409166666666668, 30.409166666666668, 31.409166666666668, 31.909166666666668, 32.409166666666664, 32.909166666666664, 33.409166666666664, 34.409166666666664, 35.409166666666664, 36.409166666666664, 37.409166666666664, 38.409166666666664, 40.409166666666664, 42.409166666666664, 42.85916666666667, 44.409166666666664, 45.409166666666664, 46.409166666666664, 47.409166666666664], 'tdata': array([[ 0. ,  0. ,  0. , ...,  0. ,  0. ,  0. ],\n",
      "       [ 0. , 95. , 53. , ..., 16.4,  0. ,  0. ],\n",
      "       [ 0. ,  0. ,  0. , ...,  0. ,  0. ,  0. ],\n",
      "       ...,\n",
      "       [ 0. ,  0. ,  0. , ...,  0. ,  0. ,  0. ],\n",
      "       [ 0. ,  0. ,  0. , ...,  0. ,  0. ,  0. ],\n",
      "       [ 0. ,  0. ,  0. , ...,  0. ,  0. ,  0. ]]), 'tmask': array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 1, 1, ..., 1, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]])}\n",
      "[ 0.      0.      0.      4.1627 10.274 ]\n"
     ]
    }
   ],
   "source": [
    "tem = np.load(data_path+\"1050_episode1.npz\")\n",
    "print(list(tem.keys()))\n",
    "for key in tem.keys():\n",
    "    print(tem[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21139,\n",
       " ['10004_episode0.npz',\n",
       "  '10007_episode0.npz',\n",
       "  '1000_episode0.npz',\n",
       "  '10011_episode0.npz',\n",
       "  '10013_episode0.npz'])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_list = os.listdir(data_path)\n",
    "files = []\n",
    "for file in files_list:\n",
    "    if file[-3:]==\"npz\":\n",
    "        files.append(file)\n",
    "files.sort()\n",
    "assert len(files)==21139,\"[x] Error: Please preprocess files again!\"\n",
    "\n",
    "len(files),files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_samples_data = []\n",
    "re_samples_mask = []\n",
    "\n",
    "ir_samples_data = []\n",
    "ir_samples_mask = []\n",
    "\n",
    "info_list = []\n",
    "label_list = []\n",
    "\n",
    "for file in files:\n",
    "    data = np.load(data_path+\"%s.npz\"%(file[:-4]))\n",
    "    info_list.append(data['info'])\n",
    "    label_list.append(data['labels'])\n",
    "    re_samples_data.append(data['regular_data'][()]['tdata'])\n",
    "    re_samples_mask.append(data['regular_data'][()]['tmask'])\n",
    "    ir_samples_data.append(data['irregular_data'][()]['tdata'])\n",
    "    ir_samples_mask.append(data['irregular_data'][()]['tmask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2909, 492, 2016, 679, 15043, 0, 9510, 11629, 0, 21139, 5370, 18181]\n",
      "Ethnicity 21139 100.0\n",
      "Gender 21139 100.0\n",
      "Age 21139 100.0\n",
      "Height 5370 25.4\n",
      "Weight 18181 86.01\n"
     ]
    }
   ],
   "source": [
    "info_dict = {}\n",
    "for i in range(12):\n",
    "    info_dict[i] = []\n",
    "for sub_info in info_list:\n",
    "    for i in range(12):\n",
    "        if sub_info[i] != -1:\n",
    "            info_dict[i].append(sub_info[i])\n",
    "\n",
    "info_result = []\n",
    "for i in range(12):\n",
    "    info_result.append(len(info_dict[i]))\n",
    "print(info_result)\n",
    "\n",
    "count = 0\n",
    "for i in range(5):\n",
    "    count+=len(info_dict[i])\n",
    "print(demo_features[0],count,round(count/211.39,2))\n",
    "count = 0\n",
    "for i in range(6,8):\n",
    "    count+=len(info_dict[i])\n",
    "print(demo_features[1],count,round(count/211.39,2))\n",
    "for i in range(9,12):\n",
    "    count = len(info_dict[i])\n",
    "    print(demo_features[i-7],count,round(count/211.39,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2797, 1238, 9175)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# row.MORTALITY_INUNIT,row.MORTALITY_INHOSPITAL,row.MORTALITY,row.LOS,row.LOS2\n",
    "label_list=np.array(label_list)\n",
    "y1 = np.array(label_list[:,1],int)\n",
    "sum(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "def get_folds(indices, array_y, num=5):\n",
    "    folds = []\n",
    "    for i in range(num):\n",
    "        index_train, index_valid_test, Y_train, Y_valid_test = train_test_split(indices, array_y, test_size=0.2, random_state=2012+i,\n",
    "                                                               shuffle=True,stratify=array_y)\n",
    "        index_valid, index_test, Y_valid, Y_test = train_test_split(index_valid_test, Y_valid_test, test_size=0.5, random_state=2012+i,\n",
    "                                                               shuffle=True,stratify=Y_valid_test)\n",
    "\n",
    "        print(\"[train] 1:%d 0:%d all:%d\" %(sum(Y_train),len(Y_train)-sum(Y_train),len(Y_train)))\n",
    "        print(\"[valid] 1:%d 0:%d all:%d\" %(sum(Y_valid),len(Y_valid)-sum(Y_valid),len(Y_valid)))\n",
    "        print(\"[test]  1:%d 0:%d all:%d\" %(sum(Y_test),len(Y_test)-sum(Y_test),len(Y_test)))\n",
    "        folds.append([index_train,index_valid,index_test])\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] 1:2238 0:14673 all:16911\n",
      "[valid] 1:280 0:1834 all:2114\n",
      "[test]  1:279 0:1835 all:2114\n",
      "[train] 1:2238 0:14673 all:16911\n",
      "[valid] 1:280 0:1834 all:2114\n",
      "[test]  1:279 0:1835 all:2114\n",
      "[train] 1:2238 0:14673 all:16911\n",
      "[valid] 1:280 0:1834 all:2114\n",
      "[test]  1:279 0:1835 all:2114\n",
      "[train] 1:2238 0:14673 all:16911\n",
      "[valid] 1:280 0:1834 all:2114\n",
      "[test]  1:279 0:1835 all:2114\n",
      "[train] 1:2238 0:14673 all:16911\n",
      "[valid] 1:279 0:1835 all:2114\n",
      "[test]  1:280 0:1834 all:2114\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[array(['7825_episode0.npz', '22816_episode0.npz', '16748_episode0.npz',\n",
       "         ..., '45374_episode0.npz', '17707_episode0.npz',\n",
       "         '7666_episode0.npz'], dtype='<U19'),\n",
       "  array(['72483_episode0.npz', '17668_episode0.npz', '85272_episode0.npz',\n",
       "         ..., '18123_episode2.npz', '31361_episode0.npz',\n",
       "         '25723_episode0.npz'], dtype='<U19'),\n",
       "  array(['5760_episode0.npz', '17859_episode1.npz', '82960_episode0.npz',\n",
       "         ..., '23118_episode0.npz', '6128_episode0.npz',\n",
       "         '24981_episode1.npz'], dtype='<U19')],\n",
       " [array(['16687_episode2.npz', '27598_episode0.npz', '99256_episode0.npz',\n",
       "         ..., '3866_episode6.npz', '20711_episode0.npz',\n",
       "         '29514_episode0.npz'], dtype='<U19'),\n",
       "  array(['30020_episode0.npz', '43004_episode0.npz', '24746_episode0.npz',\n",
       "         ..., '18483_episode0.npz', '85541_episode0.npz',\n",
       "         '23849_episode0.npz'], dtype='<U19'),\n",
       "  array(['64082_episode0.npz', '26043_episode0.npz', '25966_episode0.npz',\n",
       "         ..., '13033_episode4.npz', '77443_episode0.npz',\n",
       "         '83258_episode0.npz'], dtype='<U19')],\n",
       " [array(['30181_episode0.npz', '68389_episode2.npz', '96651_episode2.npz',\n",
       "         ..., '94525_episode2.npz', '5535_episode0.npz',\n",
       "         '3549_episode0.npz'], dtype='<U19'),\n",
       "  array(['77413_episode1.npz', '30348_episode2.npz', '18721_episode0.npz',\n",
       "         ..., '11318_episode0.npz', '24110_episode0.npz',\n",
       "         '69900_episode0.npz'], dtype='<U19'),\n",
       "  array(['11236_episode4.npz', '3220_episode0.npz', '50405_episode0.npz',\n",
       "         ..., '24678_episode0.npz', '28926_episode1.npz',\n",
       "         '83419_episode0.npz'], dtype='<U19')],\n",
       " [array(['85929_episode0.npz', '90115_episode0.npz', '98016_episode0.npz',\n",
       "         ..., '10377_episode3.npz', '60878_episode1.npz',\n",
       "         '20010_episode0.npz'], dtype='<U19'),\n",
       "  array(['27309_episode0.npz', '88214_episode0.npz', '89562_episode0.npz',\n",
       "         ..., '28996_episode0.npz', '51297_episode0.npz',\n",
       "         '41251_episode0.npz'], dtype='<U19'),\n",
       "  array(['27586_episode0.npz', '43472_episode1.npz', '16776_episode0.npz',\n",
       "         ..., '4743_episode0.npz', '86580_episode0.npz',\n",
       "         '19596_episode0.npz'], dtype='<U19')],\n",
       " [array(['32129_episode0.npz', '20750_episode0.npz', '26514_episode0.npz',\n",
       "         ..., '32725_episode0.npz', '867_episode0.npz',\n",
       "         '20568_episode0.npz'], dtype='<U19'),\n",
       "  array(['96151_episode0.npz', '73280_episode0.npz', '51038_episode0.npz',\n",
       "         ..., '77034_episode0.npz', '17206_episode0.npz',\n",
       "         '13033_episode5.npz'], dtype='<U19'),\n",
       "  array(['2769_episode0.npz', '68037_episode0.npz', '5678_episode0.npz',\n",
       "         ..., '25412_episode0.npz', '7522_episode1.npz',\n",
       "         '5195_episode0.npz'], dtype='<U19')]]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds1 = get_folds(np.array(files), y1)\n",
    "folds1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demographic infomation norm\n",
    "def get_norm_demo(info_list,folds):\n",
    "    print(\"============== norm of demographic features =================\")\n",
    "#     info_list = []\n",
    "#     for file in track(files):\n",
    "#         data = np.load(data_path+\"%s.npz\"%(file[:-4]))\n",
    "#         info_list.append(data['info'])\n",
    "#     info_array = np.array(info_list)\n",
    "        \n",
    "    demo_mean = []\n",
    "    demo_std = []\n",
    "    demo_min = []\n",
    "    demo_max = []\n",
    "    for fold_id, sub_fold in enumerate(folds):\n",
    "        print(\"fold%2d\"%fold_id)\n",
    "        sub_infos = []\n",
    "        for index in sub_fold[0]:\n",
    "            file_index = files.index(index)\n",
    "            sub_infos.append(info_list[file_index])\n",
    "        \n",
    "        info_dict = {}\n",
    "        for i in range(9,12):\n",
    "            info_dict[i] = []\n",
    "        for sub_info in sub_infos:\n",
    "            for i in range(9,12):\n",
    "                if sub_info[i] != -1:\n",
    "                    info_dict[i].append(sub_info[i])\n",
    "        # Age, height, Weight,\n",
    "        ia,ih,iw=9,10,11\n",
    "        demo_mean.append([np.average(info_dict[ia]),np.average(info_dict[ih]),np.average(info_dict[iw])])\n",
    "        demo_std.append([np.std(info_dict[ia]),np.std(info_dict[ih]),np.std(info_dict[iw])])\n",
    "        demo_min.append([np.min(info_dict[ia]),np.min(info_dict[ih]),np.min(info_dict[iw])])\n",
    "        demo_max.append([np.max(info_dict[ia]),np.max(info_dict[ih]),np.max(info_dict[iw])])\n",
    "    return {\n",
    "        \"max\": demo_max,\n",
    "        \"min\": demo_min,\n",
    "        \"avg\": demo_mean,\n",
    "        \"std\": demo_std,\n",
    "    } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_norm_result(samples_data,samples_mask,folds):\n",
    "    print(\"============== norm of time-series features =================\")\n",
    "    samples_data = np.array(samples_data)\n",
    "    samples_mask = np.array(samples_mask)\n",
    "\n",
    "    mean_mortality = []\n",
    "    std_mortality = []\n",
    "    min_mortality = []\n",
    "    max_mortality = []\n",
    "\n",
    "    for fold_id, sub_fold in enumerate(folds):\n",
    "        print(\"fold%2d\"%fold_id)\n",
    "\n",
    "        sub_data = []\n",
    "        sub_mask = []\n",
    "        for index in sub_fold[0]:\n",
    "            file_index = files.index(index)\n",
    "            sub_data.append(samples_data[file_index])\n",
    "            sub_mask.append(samples_mask[file_index])\n",
    "\n",
    "        recoders = {}\n",
    "        for key in range(len(time_features)):\n",
    "            recoders[key] = []\n",
    "\n",
    "        for i,sub in enumerate(sub_data):\n",
    "            for t,t_data in enumerate(sub):\n",
    "                for f,f_data in enumerate(t_data):\n",
    "                    if sub_mask[i][t][f] == 1:\n",
    "                        recoders[f].append(f_data)\n",
    "\n",
    "        mor_mean = []\n",
    "        mor_std = []\n",
    "        mor_min = []\n",
    "        mor_max = []\n",
    "        for key in range(len(time_features)):\n",
    "            mor_mean.append(np.mean(recoders[key]))\n",
    "            mor_std.append(np.std(recoders[key]))\n",
    "            mor_min.append(np.min(recoders[key]))\n",
    "            mor_max.append(np.max(recoders[key]))\n",
    "\n",
    "        mean_mortality.append(mor_mean)\n",
    "        std_mortality.append(mor_std)\n",
    "        min_mortality.append(mor_min)\n",
    "        max_mortality.append(mor_max)\n",
    "    return {\n",
    "        \"max\": max_mortality,\n",
    "        \"min\": min_mortality,\n",
    "        \"avg\": mean_mortality,\n",
    "        \"std\": std_mortality,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== norm of demographic features =================\n",
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "============== norm of time-series features =================\n",
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "============== norm of time-series features =================\n",
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n"
     ]
    }
   ],
   "source": [
    "demo_norm1 = get_norm_demo(info_list,folds1)\n",
    "regular_norm1 = get_norm_result(re_samples_data,re_samples_mask,folds1)\n",
    "irregular_norm1 = get_norm_result(ir_samples_data,ir_samples_mask,folds1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('inhos_mortality_folds',\n",
    "         fold_tvt = np.array(folds1),\n",
    "         input_dim = 37,\n",
    "         info_dim = 12,\n",
    "         demo_norm = demo_norm1,\n",
    "         regular_norm = regular_norm1,\n",
    "         irregular_norm = irregular_norm1,\n",
    "         time_features = time_features,\n",
    "         demo_features = demo_features,\n",
    "         diag_features = diag_features,\n",
    "         labels = np.array([\"MORTALITY_INUNIT\",\"MORTALITY_INHOSPITAL\",\"MORTALITY\",\"LOS_UNIT_UNIT\",\"LOS_UNIT_DISCHARGE\"]),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
