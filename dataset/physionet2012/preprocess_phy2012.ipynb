{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "from rich.progress import track\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wget -r -N -c -np https://physionet.org/files/challenge-2012/1.0.0/set-a.tar.gz -nd -P ./files/\n",
      "set-a.tar.gz is downloaded!\n",
      "set-a.tar.gz is unzipped!\n",
      "wget -r -N -c -np https://physionet.org/files/challenge-2012/1.0.0/set-b.tar.gz -nd -P ./files/\n",
      "set-b.tar.gz is downloaded!\n",
      "set-b.tar.gz is unzipped!\n",
      "wget -r -N -c -np https://physionet.org/files/challenge-2012/1.0.0/set-c.tar.gz -nd -P ./files/\n",
      "set-c.tar.gz is downloaded!\n",
      "set-c.tar.gz is unzipped!\n",
      "wget -r -N -c -np https://physionet.org/files/challenge-2012/1.0.0/Outcomes-a.txt -nd -P ./files/\n",
      "Outcomes-a.txt is downloaded!\n",
      "wget -r -N -c -np https://physionet.org/files/challenge-2012/1.0.0/Outcomes-b.txt -nd -P ./files/\n",
      "Outcomes-b.txt is downloaded!\n",
      "wget -r -N -c -np https://physionet.org/files/challenge-2012/1.0.0/Outcomes-c.txt -nd -P ./files/\n",
      "Outcomes-c.txt is downloaded!\n"
     ]
    }
   ],
   "source": [
    "file_path = \"./files/\"\n",
    "if not os.path.exists(file_path):\n",
    "    os.mkdir(file_path)\n",
    "    \n",
    "file_list = [\"set-a.tar.gz\",\"set-b.tar.gz\",\"set-c.tar.gz\",\"Outcomes-a.txt\",\"Outcomes-b.txt\",\"Outcomes-c.txt\"]\n",
    "for file in file_list:\n",
    "    if os.path.exists(file_path+file):\n",
    "        continue\n",
    "    os.system(\"wget -r -N -c -np https://physionet.org/files/challenge-2012/1.0.0/%s -nd -P %s\"%(file,file_path))\n",
    "    print(\"wget -r -N -c -np https://physionet.org/files/challenge-2012/1.0.0/%s -nd -P %s\"%(file,file_path))\n",
    "    print(\"%s is downloaded!\"%(file))\n",
    "    if file[-7:] == \".tar.gz\":\n",
    "        os.system(\"tar -zxvf %s/%s -C %s\"%(file_path,file,file_path))\n",
    "        print(\"%s is unzipped!\"%(file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demographic_features: 5  time_features:37 \n"
     ]
    }
   ],
   "source": [
    "demo_num_features = [\"Age\", 'Height', 'Weight']\n",
    "demo_cat_features = ['Gender', 'ICUType']\n",
    "# Gender (0: female, or 1: male)\n",
    "# ICUType (1: Coronary Care Unit, 2: Cardiac Surgery Recovery Unit, 3: Medical ICU, or 4: Surgical ICU)\n",
    "\n",
    "demographic_features = demo_num_features + demo_cat_features\n",
    "time_num_features = ['ALP', 'ALT', 'AST', 'Albumin', 'BUN', 'Bilirubin', 'Cholesterol', 'Creatinine', \n",
    "                 'DiasABP', 'FiO2', 'GCS', 'Glucose', 'HCO3', 'HCT', 'HR', 'K', 'Lactate', 'MAP', \n",
    "                 'Mg', 'NIDiasABP', 'NIMAP', 'NISysABP', 'Na', 'PaCO2', 'PaO2', \n",
    "                 'Platelets', 'RespRate', 'SaO2', 'SysABP', 'Temp', 'TroponinI', 'TroponinT', \n",
    "                 'Urine', 'WBC', 'Weight', 'pH']\n",
    "time_cat_features = ['MechVent']\n",
    "time_features = time_num_features + time_cat_features\n",
    "print('demographic_features: %d  time_features:%d ' % (len(demographic_features),len(time_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SAPS-I', 'SOFA', 'Length_of_stay', 'Survival', 'In-hospital_death']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAPS-I</th>\n",
       "      <th>SOFA</th>\n",
       "      <th>Length_of_stay</th>\n",
       "      <th>Survival</th>\n",
       "      <th>In-hospital_death</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RecordID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132539</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132540</th>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132541</th>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132543</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>575</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132545</th>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>918</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163029</th>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163033</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163034</th>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163035</th>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>71</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163037</th>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          SAPS-I  SOFA  Length_of_stay  Survival  In-hospital_death\n",
       "RecordID                                                           \n",
       "132539         6     1               5        -1                  0\n",
       "132540        16     8               8        -1                  0\n",
       "132541        21    11              19        -1                  0\n",
       "132543         7     1               9       575                  0\n",
       "132545        17     2               4       918                  0\n",
       "...          ...   ...             ...       ...                ...\n",
       "163029        18     8              17        -1                  0\n",
       "163033         9     1               9        -1                  0\n",
       "163034        13    10               8        -1                  0\n",
       "163035        20     9              71        96                  0\n",
       "163037        18     7              21        -1                  0\n",
       "\n",
       "[12000 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine labels\n",
    "label_file = ['Outcomes-a.txt','Outcomes-b.txt','Outcomes-c.txt']\n",
    "label = pd.DataFrame()\n",
    "for name in label_file:\n",
    "    tmp = pd.read_csv(file_path+name)\n",
    "    label = pd.concat([label,tmp])\n",
    "label = label.set_index('RecordID')\n",
    "name_labels = list(label.columns)\n",
    "print(name_labels)\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, ['132539.txt', '132540.txt', '132541.txt', '132543.txt', '132545.txt'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine samples \n",
    "data_path = \"./data/\"\n",
    "if not os.path.exists(data_path):\n",
    "    os.mkdir(data_path)\n",
    "\n",
    "for sub_dataset_file in ['./set-a','./set-b','./set-c']:\n",
    "    os.system(\"mv %s/%s/* %s/\"%(file_path,sub_dataset_file,data_path))\n",
    "\n",
    "files_list = os.listdir(data_path)\n",
    "files = []\n",
    "for file in files_list:\n",
    "    if file[-3:]==\"txt\":\n",
    "        files.append(file)\n",
    "files.sort()\n",
    "assert len(files)==12000,\"[x] DownloadError: Please delete files and download again!\"\n",
    "\n",
    "len(files),files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3abf2d224d1a42b9b5f26497d9c2414e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00:00', 'Gender', '-1']\n",
      "['00:00', 'Gender', '-1']\n",
      "['00:00', 'Gender', '-1']\n",
      "['00:00', 'Gender', '-1']\n",
      "['00:00', 'Gender', '-1']\n",
      "['00:00', 'Gender', '-1']\n",
      "['00:00', 'Gender', '-1']\n",
      "['00:00', 'Gender', '-1']\n",
      "['00:00', 'Gender', '-1']\n",
      "['00:00', 'Gender', '-1']\n",
      "['00:00', 'Gender', '-1']\n",
      "['00:00', 'Gender', '-1']\n"
     ]
    }
   ],
   "source": [
    "# generate irregular dataset\n",
    "\n",
    "def process_sample(file):\n",
    "    admission_id = int(file[:-4])\n",
    "    f = open(data_path+file)\n",
    "    lines = f.readlines()\n",
    "    sample_info = np.full(fill_value=-1,shape=len(demo_num_features)+2+4).tolist()\n",
    "    \n",
    "    sample_re_stime = [3600*i for i in range(48)]\n",
    "    sample_re_tdata = np.full((48,len(time_features)),0.0)\n",
    "    sample_re_tmask = np.full((48,len(time_features)),0.0)\n",
    "    \n",
    "    sample_ir_stime = []\n",
    "    sample_ir_tdata = []\n",
    "    sample_ir_tmask = []\n",
    "\n",
    "    for line in lines[1:]:\n",
    "        record = line[:-1].split(\",\")\n",
    "        stime = record[0].split(\":\")\n",
    "        time = (int(stime[0])*60 + int(stime[1]))*60\n",
    "        \n",
    "        if time not in sample_ir_stime:\n",
    "            sample_ir_stime.append(time)\n",
    "            sample_ir_tdata.append(np.full(len(time_features),0.0))\n",
    "            sample_ir_tmask.append(np.full(len(time_features),0.0))\n",
    "        \n",
    "        t_index = sample_ir_stime.index(time)\n",
    "        if record[1] in demographic_features and time==0:\n",
    "            f_index = demographic_features.index(record[1])\n",
    "            if f_index < len(demo_num_features):\n",
    "                if f_index == 1 and float(record[2]) < 100:\n",
    "                    continue\n",
    "                elif f_index == 2 and float(record[2]) < 30:\n",
    "                    continue\n",
    "                sample_info[f_index] = float(record[2])\n",
    "            elif record[1] == demo_cat_features[0] and float(record[2])!=-1:\n",
    "                sample_info[len(demo_num_features)+int(record[2])] = 1\n",
    "            elif record[1] == demo_cat_features[1] and float(record[2])!=-1:\n",
    "                sample_info[len(demo_num_features)+int(record[2])+1] = 1\n",
    "            else:\n",
    "                print(record)\n",
    "                \n",
    "        elif record[1] in time_features and record[2]!='':\n",
    "            f_index = time_features.index(record[1])\n",
    "\n",
    "            # outcome-related descriptors are non-negative (â‰¥ 0)#####    \n",
    "            if float(record[2])<0:\n",
    "                continue\n",
    "            # pH > 5 and pH < 8 \n",
    "            if f_index==time_features.index('pH') and  (float(record[2])<5 or float(record[2])>8):\n",
    "                continue\n",
    "            # Weight > 10 \n",
    "            if f_index==time_features.index('Weight') and  (float(record[2])<10 ):\n",
    "                continue\n",
    "            # Temp > 10 \n",
    "            if f_index==time_features.index('Temp') and  (float(record[2])<10 ):\n",
    "                continue\n",
    "\n",
    "            f_index = time_features.index(record[1])\n",
    "            sample_ir_tdata[t_index][f_index]= float(record[2])\n",
    "            sample_ir_tmask[t_index][f_index]= 1\n",
    "            \n",
    "            regular_time_index = int((time-1)/3600)\n",
    "            sample_re_tdata[regular_time_index][f_index]= float(record[2])\n",
    "            sample_re_tmask[regular_time_index][f_index]= 1\n",
    "\n",
    "    admission_label = list(label.loc[admission_id])\n",
    "    \n",
    "    np.savez(data_path+str(admission_id),\n",
    "             info = sample_info,\n",
    "             regular_data = {\n",
    "                 \"stime\": sample_re_stime,\n",
    "                 \"tdata\": sample_re_tdata,\n",
    "                 \"tmask\": sample_re_tmask,\n",
    "             },\n",
    "             irregular_data = {\n",
    "                 \"stime\": sample_ir_stime,\n",
    "                 \"tdata\": sample_ir_tdata,\n",
    "                 \"tmask\": sample_ir_tmask,\n",
    "             },\n",
    "\n",
    "             labels = admission_label,\n",
    "            )\n",
    "    \n",
    "for file in track(files):\n",
    "    process_sample(file)\n",
    "# process_sample(\"137392.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([132539, 132540, 132541, ..., 163034, 163035, 163037]),\n",
       " array([0, 0, 0, ..., 0, 0, 0]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(label.index),np.array(label['In-hospital_death'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "def get_folds(indices, array_y, num=5):\n",
    "    folds = []\n",
    "    for i in range(num):\n",
    "        index_train, index_valid_test, Y_train, Y_valid_test = train_test_split(indices, array_y, test_size=0.2, random_state=2012+i,\n",
    "                                                               shuffle=True,stratify=array_y)\n",
    "        index_valid, index_test, Y_valid, Y_test = train_test_split(index_valid_test, Y_valid_test, test_size=0.5, random_state=2012+i,\n",
    "                                                               shuffle=True,stratify=Y_valid_test)\n",
    "\n",
    "        print(\"[train] 1:%d 0:%d all:%d\" %(sum(Y_train),len(Y_train)-sum(Y_train),len(Y_train)))\n",
    "        print(\"[valid] 1:%d 0:%d all:%d\" %(sum(Y_valid),len(Y_valid)-sum(Y_valid),len(Y_valid)))\n",
    "        print(\"[test]  1:%d 0:%d all:%d\" %(sum(Y_test),len(Y_test)-sum(Y_test),len(Y_test)))\n",
    "        folds.append([index_train,index_valid,index_test])\n",
    "    return folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] 1:1366 0:8234 all:9600\n",
      "[valid] 1:171 0:1029 all:1200\n",
      "[test]  1:170 0:1030 all:1200\n",
      "[train] 1:1366 0:8234 all:9600\n",
      "[valid] 1:171 0:1029 all:1200\n",
      "[test]  1:170 0:1030 all:1200\n",
      "[train] 1:1366 0:8234 all:9600\n",
      "[valid] 1:171 0:1029 all:1200\n",
      "[test]  1:170 0:1030 all:1200\n",
      "[train] 1:1366 0:8234 all:9600\n",
      "[valid] 1:171 0:1029 all:1200\n",
      "[test]  1:170 0:1030 all:1200\n",
      "[train] 1:1366 0:8234 all:9600\n",
      "[valid] 1:170 0:1030 all:1200\n",
      "[test]  1:171 0:1029 all:1200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[array([150491, 143937, 148710, ..., 150063, 135326, 140879]),\n",
       "  array([134391, 148241, 145189, ..., 141786, 156673, 149901]),\n",
       "  array([134205, 151033, 147324, ..., 136306, 158770, 132767])],\n",
       " [array([143784, 134576, 142356, ..., 135077, 146068, 150891]),\n",
       "  array([134063, 152733, 154494, ..., 147317, 156459, 142035]),\n",
       "  array([158157, 138649, 143646, ..., 162090, 154211, 138961])],\n",
       " [array([142332, 162316, 149033, ..., 152087, 154143, 146790]),\n",
       "  array([157594, 147753, 136638, ..., 140088, 144938, 140016]),\n",
       "  array([147204, 161066, 153946, ..., 151962, 141244, 146571])],\n",
       " [array([141183, 158862, 134157, ..., 150889, 153850, 146588]),\n",
       "  array([133023, 154329, 138378, ..., 133274, 145690, 135859]),\n",
       "  array([145172, 151441, 153697, ..., 145900, 161062, 138848])],\n",
       " [array([149092, 157974, 154688, ..., 149277, 146466, 142378]),\n",
       "  array([148798, 158168, 143387, ..., 162154, 149290, 158739]),\n",
       "  array([157204, 147736, 154271, ..., 146018, 140341, 155691])]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = np.array(label.index)\n",
    "array_y = np.array(label['In-hospital_death'])\n",
    "folds = get_folds(indices, array_y)\n",
    "folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e9dd0348bb44677a0785220acfe05e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "12000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_list = []\n",
    "for file in track(files):\n",
    "    data = np.load(data_path+\"%s.npz\"%(file[:-4]))\n",
    "    info_list.append(data['info'])\n",
    "len(info_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age 12000\n",
      "Height 6257\n",
      "Weight 10997\n",
      "Gender 11988\n",
      "ICUType 12000\n"
     ]
    }
   ],
   "source": [
    "info_dict = {}\n",
    "for i in range(9):\n",
    "    info_dict[i] = []\n",
    "for sub_info in info_list:\n",
    "    for i in range(9):\n",
    "        if sub_info[i] != -1:\n",
    "            info_dict[i].append(sub_info[i])\n",
    "print(demographic_features[0],len(info_dict[0]))\n",
    "print(demographic_features[1],len(info_dict[1]))\n",
    "print(demographic_features[2],len(info_dict[2]))\n",
    "print(demographic_features[3],len(info_dict[3]+info_dict[4]))\n",
    "print(demographic_features[4],len(info_dict[5] + info_dict[6] +  info_dict[7] + info_dict[8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135757.txt [ 43.  180.3 123.   -1.   -1.   -1.   -1.    1.   -1. ]\n",
      "137392.txt [43. -1. -1. -1. -1. -1. -1.  1. -1.]\n",
      "141486.txt [85.  -1.  56.7 -1.  -1.  -1.  -1.  -1.   1. ]\n",
      "143896.txt [47.  -1.  49.9 -1.  -1.  -1.  -1.   1.  -1. ]\n",
      "144078.txt [86.  -1.  59.8 -1.  -1.  -1.  -1.   1.  -1. ]\n",
      "146615.txt [34.  -1.  73.8 -1.  -1.  -1.  -1.   1.  -1. ]\n",
      "147570.txt [ 38.   -1.  133.6  -1.   -1.   -1.   -1.    1.   -1. ]\n",
      "148436.txt [ 78.  185.4  83.7  -1.   -1.   -1.    1.   -1.   -1. ]\n",
      "156222.txt [ 26.  188.   97.7  -1.   -1.   -1.    1.   -1.   -1. ]\n",
      "156244.txt [59. -1. -1. -1. -1. -1.  1. -1. -1.]\n",
      "156818.txt [79. -1. -1. -1. -1. -1. -1.  1. -1.]\n",
      "160470.txt [78. -1. -1. -1. -1. -1. -1.  1. -1.]\n"
     ]
    }
   ],
   "source": [
    "# missing gender\n",
    "for i,sub_info in enumerate(info_list):\n",
    "    if sub_info[3] + sub_info[4] == -2:\n",
    "        print(files[i], sub_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demographic infomation norm\n",
    "def get_norm_demo(info_list,folds):\n",
    "    print(\"============== norm of demographic features =================\")\n",
    "#     info_list = []\n",
    "#     for file in track(files):\n",
    "#         data = np.load(data_path+\"%s.npz\"%(file[:-4]))\n",
    "#         info_list.append(data['info'])\n",
    "#     info_array = np.array(info_list)\n",
    "        \n",
    "    demo_mean = []\n",
    "    demo_std = []\n",
    "    demo_min = []\n",
    "    demo_max = []\n",
    "    for fold_id, sub_fold in enumerate(folds):\n",
    "        print(\"fold%2d\"%fold_id)\n",
    "        sub_infos = []\n",
    "        for index in sub_fold[0]:\n",
    "            file_index = files.index(\"%s.txt\"%index)\n",
    "            sub_infos.append(info_list[file_index])\n",
    "\n",
    "        info_dict = {}\n",
    "        for i in range(9):\n",
    "            info_dict[i] = []\n",
    "        for sub_info in sub_infos:\n",
    "            for i in range(9):\n",
    "                if sub_info[i] != -1:\n",
    "                    info_dict[i].append(sub_info[i])\n",
    "        \n",
    "        demo_mean.append([np.average(info_dict[0]),np.average(info_dict[1]),np.average(info_dict[2])])\n",
    "        demo_std.append([np.std(info_dict[0]),np.std(info_dict[1]),np.std(info_dict[2])])\n",
    "        demo_min.append([np.min(info_dict[0]),np.min(info_dict[1]),np.min(info_dict[2])])\n",
    "        demo_max.append([np.max(info_dict[0]),np.max(info_dict[1]),np.max(info_dict[2])])\n",
    "    return {\n",
    "        \"max\": demo_max,\n",
    "        \"min\": demo_min,\n",
    "        \"avg\": demo_mean,\n",
    "        \"std\": demo_std,\n",
    "    } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_norm_result(samples_data,samples_mask,folds):\n",
    "    print(\"============== norm of time-series features =================\")\n",
    "    samples_data = np.array(samples_data)\n",
    "    samples_mask = np.array(samples_mask)\n",
    "\n",
    "    mean_mortality = []\n",
    "    std_mortality = []\n",
    "    min_mortality = []\n",
    "    max_mortality = []\n",
    "\n",
    "    for fold_id, sub_fold in enumerate(folds):\n",
    "        print(\"fold%2d\"%fold_id)\n",
    "\n",
    "        sub_data = []\n",
    "        sub_mask = []\n",
    "        for index in sub_fold[0]:\n",
    "            file_index = files.index(\"%s.txt\"%index)\n",
    "            sub_data.append(samples_data[file_index])\n",
    "            sub_mask.append(samples_mask[file_index])\n",
    "\n",
    "        recoders = {}\n",
    "        for key in range(len(time_features)):\n",
    "            recoders[key] = []\n",
    "\n",
    "        for i,sub in enumerate(sub_data):\n",
    "            for t,t_data in enumerate(sub):\n",
    "                for f,f_data in enumerate(t_data):\n",
    "                    if sub_mask[i][t][f] == 1:\n",
    "                        recoders[f].append(f_data)\n",
    "\n",
    "        mor_mean = []\n",
    "        mor_std = []\n",
    "        mor_min = []\n",
    "        mor_max = []\n",
    "        for key in range(len(time_features)):\n",
    "            if key < len(time_num_features):\n",
    "                mor_mean.append(np.mean(recoders[key]))\n",
    "                mor_std.append(np.std(recoders[key]))\n",
    "                mor_min.append(np.min(recoders[key]))\n",
    "                mor_max.append(np.max(recoders[key]))\n",
    "            if key >= len(time_num_features):\n",
    "                mor_mean.append(0)\n",
    "                mor_std.append(1)\n",
    "                mor_min.append(0)\n",
    "                mor_max.append(1)\n",
    "\n",
    "        mean_mortality.append(mor_mean)\n",
    "        std_mortality.append(mor_std)\n",
    "        min_mortality.append(mor_min)\n",
    "        max_mortality.append(mor_max)\n",
    "    return {\n",
    "        \"max\": max_mortality,\n",
    "        \"min\": min_mortality,\n",
    "        \"avg\": mean_mortality,\n",
    "        \"std\": std_mortality,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_samples_data = []\n",
    "re_samples_mask = []\n",
    "\n",
    "ir_samples_data = []\n",
    "ir_samples_mask = []\n",
    "\n",
    "for file in files:\n",
    "    data = np.load(data_path+\"%s.npz\"%(file[:-4]))\n",
    "    re_samples_data.append(data['regular_data'][()]['tdata'])\n",
    "    re_samples_mask.append(data['regular_data'][()]['tmask'])\n",
    "    ir_samples_data.append(data['irregular_data'][()]['tdata'])\n",
    "    ir_samples_mask.append(data['irregular_data'][()]['tmask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== norm of demographic features =================\n",
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "============== norm of time-series features =================\n",
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "============== norm of time-series features =================\n",
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n"
     ]
    }
   ],
   "source": [
    "demo_norm = get_norm_demo(info_list,folds)\n",
    "regular_norm = get_norm_result(re_samples_data,re_samples_mask,folds)\n",
    "irregular_norm = get_norm_result(ir_samples_data,ir_samples_mask,folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('inhos_mortality_folds',\n",
    "         fold_tvt = np.array(folds),\n",
    "         input_dim = 37,\n",
    "         info_dim = 9,\n",
    "         demo_norm = demo_norm,\n",
    "         regular_norm = regular_norm,\n",
    "         irregular_norm = irregular_norm,\n",
    "         time_features = {\n",
    "             \"num_features\": time_num_features,\n",
    "             \"cat_features\": time_cat_features, \n",
    "         },\n",
    "         demo_features = {\n",
    "             \"num_features\": demo_num_features,\n",
    "             \"cat_features\": demo_cat_features, \n",
    "         },\n",
    "         labels = name_labels,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fold_tvt',\n",
       " 'input_dim',\n",
       " 'info_dim',\n",
       " 'demo_norm',\n",
       " 'regular_norm',\n",
       " 'irregular_norm',\n",
       " 'time_features',\n",
       " 'demo_features']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = np.load(\"inhos_mortality_folds.npz\")\n",
    "list(temp.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# os.system(\"rm %s/*.txt\"%(data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
